{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38365d44",
   "metadata": {
    "id": "38365d44"
   },
   "source": [
    "# **Marketing Campaign Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70cedf1",
   "metadata": {
    "id": "b70cedf1"
   },
   "source": [
    "## **Problem Definition**\n",
    "\n",
    "### **The Context:**\n",
    "\n",
    " - Why is this problem important to solve?\n",
    "\n",
    "### **The objective:**\n",
    "\n",
    " - What is the intended goal?\n",
    "\n",
    "### **The key questions:**\n",
    "\n",
    "- What are the key questions that need to be answered?\n",
    "\n",
    "### **The problem formulation**:\n",
    "\n",
    "- What is it that we are trying to solve using data science?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd434483",
   "metadata": {
    "id": "bd434483"
   },
   "source": [
    "------------------------------\n",
    "## **Data Dictionary**\n",
    "------------------------------\n",
    "\n",
    "The dataset contains the following features:\n",
    "\n",
    "1. ID: Unique ID of each customer\n",
    "2. Year_Birth: Customer’s year of birth\n",
    "3. Education: Customer's level of education\n",
    "4. Marital_Status: Customer's marital status\n",
    "5. Kidhome: Number of small children in customer's household\n",
    "6. Teenhome: Number of teenagers in customer's household\n",
    "7. Income: Customer's yearly household income in USD\n",
    "8. Recency: Number of days since the last purchase\n",
    "9. Dt_Customer: Date of customer's enrollment with the company\n",
    "10. MntFishProducts: The amount spent on fish products in the last 2 years\n",
    "11. MntMeatProducts: The amount spent on meat products in the last 2 years\n",
    "12. MntFruits: The amount spent on fruits products in the last 2 years\n",
    "13. MntSweetProducts: Amount spent on sweet products in the last 2 years\n",
    "14. MntWines: The amount spent on wine products in the last 2 years\n",
    "15. MntGoldProds: The amount spent on gold products in the last 2 years\n",
    "16. NumDealsPurchases: Number of purchases made with discount\n",
    "17. NumCatalogPurchases: Number of purchases made using a catalog (buying goods to be shipped through the mail)\n",
    "18. NumStorePurchases: Number of purchases made directly in stores\n",
    "19. NumWebPurchases: Number of purchases made through the company's website\n",
    "20. NumWebVisitsMonth: Number of visits to the company's website in the last month\n",
    "21. AcceptedCmp1: 1 if customer accepted the offer in the first campaign, 0 otherwise\n",
    "22. AcceptedCmp2: 1 if customer accepted the offer in the second campaign, 0 otherwise\n",
    "23. AcceptedCmp3: 1 if customer accepted the offer in the third campaign, 0 otherwise\n",
    "24. AcceptedCmp4: 1 if customer accepted the offer in the fourth campaign, 0 otherwise\n",
    "25. AcceptedCmp5: 1 if customer accepted the offer in the fifth campaign, 0 otherwise\n",
    "26. Response: 1 if customer accepted the offer in the last campaign, 0 otherwise\n",
    "27. Complain: 1 If the customer complained in the last 2 years, 0 otherwise\n",
    "\n",
    "**Note:** You can assume that the data is collected in the year 2016."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b7a9d6",
   "metadata": {
    "id": "65b7a9d6"
   },
   "source": [
    "## **Important Notes**\n",
    "\n",
    "- This notebook can be considered a guide to refer to while solving the problem. The evaluation will be as per the Rubric shared for the Milestone. Unlike previous courses, it does not follow the pattern of the graded questions in different sections. This notebook will give you a direction on what steps need to be taken in order to get a viable solution to the problem. Please note that this is just one way of doing this. There can be other 'creative' ways to solve the problem and we urge you to feel free and explore them as an 'optional' exercise. \n",
    "\n",
    "- In the notebook, there are markdown cells called - Observations and Insights. It is a good practice to provide observations and extract insights from the outputs.\n",
    "\n",
    "- The naming convention for different variables can vary. Please consider the code provided in this notebook as a sample code.\n",
    "\n",
    "- All the outputs in the notebook are just for reference and can be different if you follow a different approach.\n",
    "\n",
    "- There are sections called **Think About It** in the notebook that will help you get a better understanding of the reasoning behind a particular technique/step. Interested learners can take alternative approaches if they wish to explore different techniques. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vEUKOiz5-Qld",
   "metadata": {
    "id": "vEUKOiz5-Qld"
   },
   "source": [
    "### **Loading Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4297cf5d",
   "metadata": {
    "id": "4297cf5d"
   },
   "outputs": [],
   "source": [
    "# Libraries to help with reading and manipulating data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Libraries to help with data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# To scale the data using z-score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# To compute distances\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# To perform K-means clustering and compute Silhouette scores\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# To visualize the elbow curve and Silhouette scores\n",
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "\n",
    "# Importing PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# To encode the variable\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Importing TSNE\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# To perform hierarchical clustering, compute cophenetic correlation, and create dendrograms\n",
    "from sklearn.cluster import AgglomerativeClustering, DBSCAN\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, cophenet\n",
    "\n",
    "# To compute distances\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "# To import K-Medoids\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "# To import Gaussian Mixture\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# To supress warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZAEqtrQu-VzO",
   "metadata": {
    "id": "ZAEqtrQu-VzO"
   },
   "source": [
    "### **Let us load the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b39cc0",
   "metadata": {
    "id": "70b39cc0"
   },
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "data = pd.read_csv(\"marketing_campaign.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e64e53a",
   "metadata": {
    "id": "3e64e53a"
   },
   "source": [
    "### **Check the shape of the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94b4947",
   "metadata": {
    "id": "e94b4947"
   },
   "outputs": [],
   "source": [
    "# Print the shape of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "O9rtKHxB-fy1",
   "metadata": {
    "id": "O9rtKHxB-fy1"
   },
   "source": [
    "#### **Observations and Insights: _____**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6BoKgZyQ-nAF",
   "metadata": {
    "id": "6BoKgZyQ-nAF"
   },
   "source": [
    "### **Understand the data by observing a few rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd1bc4b",
   "metadata": {
    "id": "9cd1bc4b"
   },
   "outputs": [],
   "source": [
    "# View first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c417a660",
   "metadata": {
    "id": "c417a660"
   },
   "outputs": [],
   "source": [
    "# View last 5 rows Hint: Use tail() method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18d7cee",
   "metadata": {
    "id": "e18d7cee"
   },
   "source": [
    "#### **Observations and Insights: _____**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c9e095",
   "metadata": {
    "id": "b4c9e095"
   },
   "source": [
    "### **Let us check the data types and and missing values of each column** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14a018a",
   "metadata": {
    "id": "c14a018a"
   },
   "outputs": [],
   "source": [
    "# Check the datatypes of each column. Hint: Use info() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1e81dd",
   "metadata": {
    "id": "5b1e81dd"
   },
   "outputs": [],
   "source": [
    "# Find the percentage of missing values in each column of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae64b672",
   "metadata": {
    "id": "ae64b672"
   },
   "source": [
    "#### **Observations and Insights: _____**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375397e7",
   "metadata": {
    "id": "375397e7"
   },
   "source": [
    "We can observe that `ID` has no null values. Also the number of unique values are equal to the number of observations. So, `ID` looks like an index for the data entry and such a column would not be useful in providing any predictive power for our analysis. Hence, it can be dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01418e2",
   "metadata": {
    "id": "a01418e2"
   },
   "source": [
    "**Dropping the ID column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b25be10",
   "metadata": {
    "id": "3b25be10"
   },
   "outputs": [],
   "source": [
    "# Remove ID column from data. Hint: Use inplace = True\n",
    "data.drop(_______)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835c10c4",
   "metadata": {
    "id": "835c10c4"
   },
   "source": [
    "## **Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e047d85",
   "metadata": {
    "id": "0e047d85"
   },
   "source": [
    "### **Let us now explore the summary statistics of numerical variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ceba1e",
   "metadata": {
    "id": "c9ceba1e"
   },
   "outputs": [],
   "source": [
    "# Explore basic summary statistics of numeric variables. Hint: Use describe() method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2963b2",
   "metadata": {
    "id": "fd2963b2"
   },
   "source": [
    "#### **Observations and Insights: _____**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fa40ad",
   "metadata": {
    "id": "63fa40ad"
   },
   "source": [
    "### **Let us also explore the summary statistics of all categorical variables and the number of unique observations in each category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac583e5c",
   "metadata": {
    "id": "ac583e5c"
   },
   "outputs": [],
   "source": [
    "# List of the categorical columns in the data\n",
    "cols = [\"Education\", \"Marital_Status\", \"Kidhome\", \"Teenhome\", \"Complain\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b8b46e",
   "metadata": {
    "id": "45b8b46e"
   },
   "source": [
    "**Number of unique observations in each category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51adf97",
   "metadata": {
    "id": "c51adf97"
   },
   "outputs": [],
   "source": [
    "for column in cols:\n",
    "    print(\"Unique values in\", column, \"are :\")\n",
    "    print(data[column].____________)\n",
    "    print(\"*\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b75da6",
   "metadata": {
    "id": "73b75da6"
   },
   "source": [
    "#### **Observations and Insights: _____**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0df3d2",
   "metadata": {
    "id": "5e0df3d2"
   },
   "source": [
    "**Think About It:**\n",
    "\n",
    "- We could observe from the summary statistics of categorical variables that the Education variable has 5 categories. Are all categories different from each other or can we combine some categories? Is 2n Cycle different from Master? \n",
    "- Similarly, there are 8 categories in Marital_Status with some categories having very low count of less than 5. Can we combine these categories with other categories? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c1bd02",
   "metadata": {
    "id": "f7c1bd02"
   },
   "source": [
    "### **Let us replace  the \"2n Cycle\" category with \"Master\" in Education and \"Alone\", \"Absurd, and \"YOLO\" with \"Single\" in Marital_Status**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd493443",
   "metadata": {
    "id": "fd493443"
   },
   "outputs": [],
   "source": [
    "# Replace the category \"2n Cycle\" with the category \"Master\"\n",
    "\n",
    "data[\"Education\"]._____________  # Hint: Use the replace() method and inplace=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3e1ae4",
   "metadata": {
    "id": "de3e1ae4"
   },
   "outputs": [],
   "source": [
    "# Replace the categories \"Alone\", \"Abusrd\", \"YOLO\" with the category \"Single\"\n",
    "\n",
    "data[\"Marital_Status\"]._______________  # Hint: Use the replace() method and inplace=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356c9bc7",
   "metadata": {
    "id": "356c9bc7"
   },
   "source": [
    "## **Univariate Analysis**\n",
    "Univariate analysis is used to explore each variable in a data set, separately. It looks at the range of values, as well as the central tendency of the values. It can be done for both numerical and categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b75f017",
   "metadata": {
    "id": "3b75f017"
   },
   "source": [
    "## **1. Univariate Analysis - Numerical Data**\n",
    "Histograms help to visualize and describe numerical data. We can also use other plots like box plot to analyze the numerical columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kY9pS6xKQkRA",
   "metadata": {
    "id": "kY9pS6xKQkRA"
   },
   "source": [
    "#### Let us plot histogram for the feature 'Income' to understand the distribution and outliers, if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b313c47f",
   "metadata": {
    "id": "b313c47f"
   },
   "outputs": [],
   "source": [
    "# Create histogram for the Income feature\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "sns.histplot(x=_________, data=__________)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e804630f",
   "metadata": {
    "id": "e804630f"
   },
   "source": [
    "**We could observe some extreme value on the right side of the distribution of the 'Income' feature. Let's use a box plot as it is more suitable to identify extreme values in the data.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a79ed8f",
   "metadata": {
    "id": "0a79ed8f"
   },
   "outputs": [],
   "source": [
    "# Plot the boxplot\n",
    "sns.__________(data=_______, x=_________, showmeans=True, color=\"violet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9220096a",
   "metadata": {
    "id": "9220096a"
   },
   "source": [
    "#### **Observations and Insights: _____**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c75b036",
   "metadata": {
    "id": "4c75b036"
   },
   "source": [
    "**Think About It**\n",
    "\n",
    "- The histogram and the box plot are showing some extreme value on the right side of the distribution of the 'Income' feature. Can we consider them as outliers and remove or should we analyze these extreme values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1f2aeb",
   "metadata": {
    "id": "2d1f2aeb"
   },
   "outputs": [],
   "source": [
    "# Calculating the upper whisker for the Income variable\n",
    "\n",
    "Q1 = data.quantile(q=0.25)                          # Finding the first quartile\n",
    "\n",
    "Q3 = _____________________                          # Finding the third quartile\n",
    "\n",
    "IQR = _______                                       # Finding the Inter Quartile Range\n",
    "\n",
    "upper_whisker = (Q3 + 1.5 * IQR)[________]          # Calculating the Upper Whisker for the Income variable\n",
    "\n",
    "print(upper_whisker)                                # Printing Upper Whisker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74c8074",
   "metadata": {
    "id": "e74c8074"
   },
   "outputs": [],
   "source": [
    "# Let's check the observations with extreme value for the Income variable\n",
    "data[data.Income > upper_whisker]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e28a104",
   "metadata": {
    "id": "4e28a104"
   },
   "source": [
    "**Think About It:**\n",
    "\n",
    "- We observed that there are only a few rows with extreme values for the Income variable. Is that enough information to treat (or not to treat) them? Do we know at what percentile the upper whisker lies? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7fdfaf",
   "metadata": {
    "id": "ad7fdfaf"
   },
   "outputs": [],
   "source": [
    "# Check the 99.5% percentile value for the Income variable\n",
    "data.quantile(q=_________)[_______]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8c69dd",
   "metadata": {
    "id": "5d8c69dd"
   },
   "source": [
    "#### **Observations and Insights: _____**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e7c1f6",
   "metadata": {
    "id": "a9e7c1f6"
   },
   "outputs": [],
   "source": [
    "# Dropping observations identified as outliers \n",
    "data.drop(index=[_______________], inplace=True) # Pass the indices of the observations (separated by a comma) to drop them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af00faa6",
   "metadata": {
    "id": "af00faa6"
   },
   "source": [
    "**Now, let's check the distribution of the Income variable after dropping outliers.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fc8635",
   "metadata": {
    "id": "04fc8635"
   },
   "outputs": [],
   "source": [
    "# Plot histogram and 'Income'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8d965d",
   "metadata": {
    "id": "9e8d965d"
   },
   "outputs": [],
   "source": [
    "# Plot the histogram for 'MntWines'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a620df6f",
   "metadata": {
    "id": "a620df6f"
   },
   "outputs": [],
   "source": [
    "# Plot the histogram for 'MntFruits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e3cb1c",
   "metadata": {
    "id": "b9e3cb1c"
   },
   "outputs": [],
   "source": [
    "# Plot the histogram for 'MntMeatProducts' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a279b68",
   "metadata": {
    "id": "6a279b68"
   },
   "outputs": [],
   "source": [
    "# Plot the histogram for 'MntFishProduct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68acbdb6",
   "metadata": {
    "id": "68acbdb6"
   },
   "outputs": [],
   "source": [
    "# Plot the histogram for 'MntSweetProducts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea5701e",
   "metadata": {
    "id": "4ea5701e"
   },
   "outputs": [],
   "source": [
    "# Plot the histogram for 'MntGoldProducts'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6185ed32",
   "metadata": {
    "id": "6185ed32"
   },
   "source": [
    "#### **Note:** Try plotting histogram for different numerical features and understand how the data looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b0c818",
   "metadata": {
    "id": "78b0c818"
   },
   "source": [
    "#### **Observations and Insights for all the plots: _____**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac04d87d",
   "metadata": {
    "id": "ac04d87d"
   },
   "source": [
    "## **2. Univariate analysis - Categorical Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c6025d",
   "metadata": {
    "id": "d3c6025d"
   },
   "source": [
    "Let us write a function that will help us create bar plots that indicate the percentage for each category. This function takes the categorical column as the input and returns the bar plot for the variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074cde82",
   "metadata": {
    "id": "074cde82"
   },
   "outputs": [],
   "source": [
    "def perc_on_bar(data, z):\n",
    "    '''\n",
    "    plot\n",
    "    feature: categorical feature\n",
    "    the function won't work if a column is passed in hue parameter\n",
    "    '''\n",
    "\n",
    "    total = len(data[z])                                          # Length of the column\n",
    "    plt.figure(figsize=(15,5))\n",
    "    ax = sns.countplot(data[z],palette='Paired',order = data[z].value_counts().index)\n",
    "    for p in ax.patches:\n",
    "        percentage = '{:.1f}%'.format(100 * p.get_height()/total) # Percentage of each class of the category\n",
    "        x = p.get_x() + p.get_width() / 2 - 0.05                  # Width of the plot\n",
    "        y = p.get_y() + p.get_height()                            # Height of the plot\n",
    "        \n",
    "        ax.annotate(percentage, (x, y), size = 12)                # Annotate the percentage \n",
    "    \n",
    "    plt.show()                                                    # Show the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965a6816",
   "metadata": {
    "id": "965a6816"
   },
   "source": [
    "#### Let us plot barplot for the variable Marital_Status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96698531",
   "metadata": {
    "id": "96698531"
   },
   "outputs": [],
   "source": [
    "# Bar plot for 'Marital_Status'\n",
    "perc_on_bar(data, 'Marital_Status')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e70646",
   "metadata": {
    "id": "45e70646"
   },
   "source": [
    "#### **Note:** Explore for other categorical variables like Education, Kidhome, Teenhome, Complain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4989521",
   "metadata": {
    "id": "b4989521"
   },
   "source": [
    "#### **Observations and Insights from all plots: _____**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818f6411",
   "metadata": {
    "id": "818f6411"
   },
   "source": [
    "## **Bivariate Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e50dd4",
   "metadata": {
    "id": "64e50dd4"
   },
   "source": [
    "We have analyzed different categorical and numerical variables. Now, let's check how different variables are related to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef227873",
   "metadata": {
    "id": "ef227873"
   },
   "source": [
    "### **Correlation Heat map**\n",
    "Heat map can show a 2D correlation matrix between numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd9ab5a",
   "metadata": {
    "id": "5bd9ab5a"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))                                                        # Setting the plot size\n",
    "sns.heatmap(___________, annot=True, vmin=-1, vmax=1, fmt=\".2f\", cmap=\"Spectral\")  # Plotting the correlation plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a57dd0a",
   "metadata": {
    "id": "7a57dd0a"
   },
   "source": [
    "#### **Observations and Insights: _____**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c00607",
   "metadata": {
    "id": "16c00607"
   },
   "source": [
    "**The above correlation heatmap only shows the relationship between numerical variables. Let's check the relationship of numerical variables with categorical variables.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d99eb8",
   "metadata": {
    "id": "27d99eb8"
   },
   "source": [
    "### **Education Vs Income**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe4cad7",
   "metadata": {
    "id": "2fe4cad7"
   },
   "outputs": [],
   "source": [
    "print(sns.barplot(x=___________, y=__________, data=__________))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbdb8f0",
   "metadata": {
    "id": "0bbdb8f0"
   },
   "source": [
    "#### **Observations and Insights: _____**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9695eb",
   "metadata": {
    "id": "1c9695eb"
   },
   "source": [
    "### **Marital Status Vs Income**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151b12ca",
   "metadata": {
    "id": "151b12ca"
   },
   "outputs": [],
   "source": [
    "# Plot the bar plot for Marital_Status and Income"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e888fe34",
   "metadata": {
    "id": "e888fe34"
   },
   "source": [
    "#### **Observations and Insights: _____**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbeafd2d",
   "metadata": {
    "id": "bbeafd2d"
   },
   "source": [
    "### **Kidhome Vs Income**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378353ea",
   "metadata": {
    "id": "378353ea"
   },
   "outputs": [],
   "source": [
    "# Plot the bar plot for Kidhome and Income"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6515b240",
   "metadata": {
    "id": "6515b240"
   },
   "source": [
    "#### **Observations and Insights: _____**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e490deeb",
   "metadata": {
    "id": "e490deeb"
   },
   "source": [
    "**We can also visualize the relationship between two categorical variables.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0650b3c1",
   "metadata": {
    "id": "0650b3c1"
   },
   "source": [
    "### **Marital_Status Vs Kidhome**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801ab9be",
   "metadata": {
    "id": "801ab9be"
   },
   "outputs": [],
   "source": [
    "# Plot the bar plot for Marital_Status and Kidhome\n",
    "pd.crosstab(_________,__________).plot(kind=_________,stacked=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a631f993",
   "metadata": {
    "id": "a631f993"
   },
   "source": [
    "#### **Observations and Insights: _____**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e81e35d",
   "metadata": {
    "id": "7e81e35d"
   },
   "source": [
    "## **Feature Engineering and Data Processing**\n",
    "\n",
    "In this section, we will first prepare our dataset for analysis.\n",
    "- Creating new columns\n",
    "- Imputing missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68f9c28",
   "metadata": {
    "id": "d68f9c28"
   },
   "source": [
    "**Think About It:**\n",
    "\n",
    "- The Year_Birth column in the current format might not be very useful in our analysis. The Year_Birth column contains the information about Day, Month, and year. Can we extract the age of each customer?\n",
    "- Are there other columns which can be used to create new features?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5146558a",
   "metadata": {
    "id": "5146558a"
   },
   "source": [
    "### **Age** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fb675e",
   "metadata": {
    "id": "a3fb675e"
   },
   "outputs": [],
   "source": [
    "# Extract only the year from the Year_Birth variable and subtracting it from 2016 will give us the age of the customer at the time of data collection in 2016\n",
    "\n",
    "data[\"Age\"] = 2016 - pd.to_datetime(_____________, format=\"%Y\").apply(lambda x: x.year) \n",
    "\n",
    "# Sorting the values in ascending order \n",
    "data[\"Age\"].sort_values()                                         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7ee7a7",
   "metadata": {
    "id": "1d7ee7a7"
   },
   "source": [
    "#### **Observations and Insights: _____**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859d00a3",
   "metadata": {
    "id": "859d00a3"
   },
   "source": [
    "**Think About It:**\n",
    "\n",
    "- We could observe from the above output that there are customers with an age greater than 115. Can this be true or a data anomaly? Can we drop these observations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcfa78f",
   "metadata": {
    "id": "8dcfa78f"
   },
   "outputs": [],
   "source": [
    "# Drop the observations with age > 115\n",
    "# Hint: Use drop() method with inplace=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e0e99e",
   "metadata": {
    "id": "00e0e99e"
   },
   "source": [
    "**Now, let's check the distribution of age in the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39316fd6",
   "metadata": {
    "id": "39316fd6"
   },
   "outputs": [],
   "source": [
    "# Plot histogram to check the distribution of age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a4fc68",
   "metadata": {
    "id": "a0a4fc68"
   },
   "source": [
    "#### **Observations and Insights: _____**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd31628",
   "metadata": {
    "id": "4bd31628"
   },
   "source": [
    "### **Kids** \n",
    "* Let's create feature \"Kids\" indicating the total kids and teens in the home."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332114dd",
   "metadata": {
    "id": "332114dd"
   },
   "outputs": [],
   "source": [
    "# Add Kidhome and Teenhome variables to create the new feature called \"Kids\"\n",
    "data[\"Kids\"] = __________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07938c1",
   "metadata": {
    "id": "b07938c1"
   },
   "source": [
    "### **Family Size**\n",
    "* Let's create a new variable called 'Family Size' to find out how many members each family has.\n",
    "* For this, we need to have a look at the Marital_Status variable, and see what are the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44b6c0b",
   "metadata": {
    "id": "b44b6c0b"
   },
   "outputs": [],
   "source": [
    "# Check the unique categories in Marial_Status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bfde90",
   "metadata": {
    "id": "56bfde90"
   },
   "source": [
    "* We can combine the sub-categories Single, Divorced, Widow as \"Single\" and we can combine the sub-categories Married and Together as \"Relationship\" \n",
    "* Then we can create a new variable called \"Status\" and assign values 1 and 2 to categories Single and Relationship, respectively.\n",
    "* Then, we can use the Kids (calculated above) and the Status column to find the family size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c292479",
   "metadata": {
    "id": "6c292479"
   },
   "outputs": [],
   "source": [
    "# Replace \"Married\" and \"Together\" with \"Relationship\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dd3f98",
   "metadata": {
    "id": "c0dd3f98"
   },
   "outputs": [],
   "source": [
    "# Replace \"Divorced\" and \"Widow\" with \"Single\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797ffc5e",
   "metadata": {
    "id": "797ffc5e"
   },
   "outputs": [],
   "source": [
    "# Create a new feature called \"Status\" by replacing \"Single\" with 1 and \"Relationship\" with 2 in Marital_Status\n",
    "data[\"Status\"] = data[__________].replace({_______: 1, ___________: 2}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c2eb29",
   "metadata": {
    "id": "a1c2eb29"
   },
   "outputs": [],
   "source": [
    "# Add two variables Status and Kids to get the total number of persons in each family\n",
    "data[\"Family_Size\"] = ______________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cc3f74",
   "metadata": {
    "id": "58cc3f74"
   },
   "source": [
    "### **Expenses** \n",
    "* Let's create a new feature called \"Expenses\", indicating the total amount spent by the customers in various products over the span of two years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c692315",
   "metadata": {
    "id": "2c692315"
   },
   "outputs": [],
   "source": [
    "# Create a new feature\n",
    "# Add the amount spent on each of product 'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds'\n",
    "data[\"Expenses\"] = ______________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e22798",
   "metadata": {
    "id": "18e22798"
   },
   "source": [
    "### **Total Purchases**\n",
    "* Let's create a new feature called \"NumTotalPurchases\", indicating the total number of products purchased by the customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906b0565",
   "metadata": {
    "id": "906b0565"
   },
   "outputs": [],
   "source": [
    "# Create a new feature\n",
    "# Add the number of purchases from each channel 'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases'\n",
    "data[\"NumTotalPurchases\"] = ____________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ff39bc",
   "metadata": {
    "id": "28ff39bc"
   },
   "source": [
    "### **Engaged in Days**\n",
    "* Let's create a new feature called \"Engaged in days\", indicating how long the customer has been with the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf1e20e",
   "metadata": {
    "id": "6bf1e20e"
   },
   "outputs": [],
   "source": [
    "# Converting Dt_customer variable to Python date time object\n",
    "data[\"Dt_Customer\"] = pd.to_datetime(____________) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ba9161",
   "metadata": {
    "id": "41ba9161"
   },
   "source": [
    "**Let's check the max and min of the date.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54b70cd",
   "metadata": {
    "id": "d54b70cd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the minimum of the date\n",
    "# Hint: Use the min() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecdbf89",
   "metadata": {
    "id": "8ecdbf89",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the maximum of the date\n",
    "# Hint: Use the max() method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8eed51",
   "metadata": {
    "id": "0a8eed51"
   },
   "source": [
    "**Think About It:**\n",
    "- From the above output from the max function, we observed that the last customer enrollment date is December 6th, 2014. Can we extract the number of days a customer has been with the company using some date as the threshold? Can January 1st, 2015 be that threshold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc01a9c",
   "metadata": {
    "id": "dfc01a9c"
   },
   "outputs": [],
   "source": [
    " # Assigning date to the day variable\n",
    "data[\"day\"] = \"01-01-2015\"                         \n",
    "\n",
    "# Converting the variable day to Python datetime object\n",
    "data[\"day\"] = pd.to_datetime(data.day)              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bd9f4a",
   "metadata": {
    "id": "f3bd9f4a"
   },
   "outputs": [],
   "source": [
    "data[\"Engaged_in_days\"] = (data[\"day\"] - data[\"Dt_Customer\"]).dt.days     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05feb89e",
   "metadata": {
    "id": "05feb89e"
   },
   "source": [
    "### **TotalAcceptedCmp**\n",
    "* Let's create a new feature called \"TotalAcceptedCmp\" that shows how many offers customers have accepted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb28da8",
   "metadata": {
    "id": "2fb28da8"
   },
   "outputs": [],
   "source": [
    "# Add all the campaign related variables to get the total number of accepted campaigns by a customer\n",
    "# \"AcceptedCmp1\", \"AcceptedCmp2\", \"AcceptedCmp3\", \"AcceptedCmp4\", \"AcceptedCmp5\", \"Response\"\n",
    "data[\"TotalAcceptedCmp\"] = __________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2193db3",
   "metadata": {
    "id": "d2193db3"
   },
   "source": [
    "### **AmountPerPurchase**\n",
    "* Let's create a new feature called \"AmountPerPurchase\" indicating the amount spent per purchase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff93c706",
   "metadata": {
    "id": "ff93c706"
   },
   "outputs": [],
   "source": [
    "# Divide the \"Expenses\" by \"NumTotalPurchases\" to create the new feature AmountPerPurchase \n",
    "data['AmountPerPurchase'] = ________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b9ee71",
   "metadata": {
    "id": "52b9ee71"
   },
   "source": [
    "**Now, let's check the maximum value of the AmountPerPurchase.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3583b89",
   "metadata": {
    "id": "f3583b89"
   },
   "outputs": [],
   "source": [
    "# Check the max value\n",
    "# Hint: Use max() function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf0f01b",
   "metadata": {
    "id": "3cf0f01b"
   },
   "source": [
    "**Think About It:**\n",
    "\n",
    "- Is the maximum value in the above output valid? What could be the potential reason for such output?\n",
    "- How many such values are there? Can we drop such observations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c4407c",
   "metadata": {
    "id": "d3c4407c"
   },
   "outputs": [],
   "source": [
    "# Find how many observations have NumTotalPurchases equal to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b4529e",
   "metadata": {
    "id": "78b4529e"
   },
   "outputs": [],
   "source": [
    "# Drop the observations with NumTotalPurchases equal to 0, using their indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffba995d",
   "metadata": {
    "id": "ffba995d"
   },
   "source": [
    "**Now, let's check the distribution of values in AmountPerPurchase column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc682e26",
   "metadata": {
    "id": "fc682e26"
   },
   "outputs": [],
   "source": [
    "# Check the summary statistics of the AmountPerPurchase variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5de5de5",
   "metadata": {
    "id": "c5de5de5"
   },
   "outputs": [],
   "source": [
    "# Plot the histogram for the AmountPerPurchas variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e75013",
   "metadata": {
    "id": "40e75013"
   },
   "source": [
    "#### **Observations and Insights: _____**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49975b70",
   "metadata": {
    "id": "49975b70"
   },
   "source": [
    "### **Imputing Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741d5135",
   "metadata": {
    "id": "741d5135"
   },
   "outputs": [],
   "source": [
    "# Impute the missing values for the Income variable with the median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba3899e",
   "metadata": {
    "id": "cba3899e"
   },
   "source": [
    "**Now that we are done with data preprocessing, let's visualize new features against the new income variable we have after imputing missing values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e7c103",
   "metadata": {
    "id": "41e7c103"
   },
   "source": [
    "### **Income Vs Expenses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1ce281",
   "metadata": {
    "id": "eb1ce281"
   },
   "outputs": [],
   "source": [
    "# Plot the scatter plot with Expenses on Y-axis and Income on X-axis  \n",
    "\n",
    "plt.figure(figsize=(20, 10))                                    # Setting the plot size\n",
    "\n",
    "sns.____________________                                        # Hint: Use sns.scatterplot()  \n",
    "\n",
    "plt.xticks(fontsize=16)                                         # Font size of X-label\n",
    "\n",
    "plt.yticks(fontsize=16)                                         # Font size of Y-label\n",
    "\n",
    "plt.xlabel(\"Income\", fontsize=20, labelpad=20)                  # Title of X-axis\n",
    "\n",
    "plt.ylabel(\"Expenses\", fontsize=20, labelpad=20)                # Title of Y-axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09f35db",
   "metadata": {
    "id": "e09f35db"
   },
   "source": [
    "#### **Observations and Insights: _____**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72064877",
   "metadata": {
    "id": "72064877"
   },
   "source": [
    "### **Family Size Vs Income**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d4b877",
   "metadata": {
    "id": "e6d4b877"
   },
   "outputs": [],
   "source": [
    "# Plot the bar plot for Family Size on X-axis and Income on Y-axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dd0473",
   "metadata": {
    "id": "98dd0473"
   },
   "source": [
    "#### **Observations and Insights: _____**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fded39",
   "metadata": {
    "id": "98fded39"
   },
   "source": [
    "## **Important Insights from EDA and Data Preprocessing**\n",
    "\n",
    "What are the the most important observations and insights from the data based on the EDA and Data Preprocessing performed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac2abaf",
   "metadata": {
    "id": "fac2abaf"
   },
   "source": [
    "## Preparing Data for Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f7bad9",
   "metadata": {
    "id": "37f7bad9"
   },
   "source": [
    "### Dropping columns that we will not use for segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec456758",
   "metadata": {
    "id": "ec456758"
   },
   "source": [
    "The decision about which variables to use for clustering is a critically important decision that will have a big impact on the clustering solution. So we need to think carefully about the variables we will choose for clustering. Clearly, this is a step where a lot of contextual knowledge, creativity, and experimentation/iterations are needed.\n",
    "\n",
    "Moreover, we often use only a few of the data attributes for segmentation (the segmentation attributes) and use some of the remaining ones (the profiling attributes) only to profile the clusters. For example, in market research and market segmentation, we can use behavioral data for segmentation (to segment the customers based on their behavior like amount spent, units bought, etc.), and then use both demographic as well as behavioral data for profiling the segments found.\n",
    "\n",
    "Here, we will use the behavioral attributes for segmentation and drop the demographic attributes like Income, Age, and Family_Size. In addition to this, we need to drop some other columns which are mentioned below.\n",
    "\n",
    "* `Dt_Customer`: We have created the `Engaged_in_days` variable using the Dt_Customer variable. Hence, we can drop this variable as it will not help with segmentation.\n",
    "* `Complain`: About 95% of the customers didn't complain and have the same value for this column. This variable will not have a major impact on segmentation. Hence, we can drop this variable. \n",
    "* `day`:  We have created the `Engaged_in_days` variable using the 'day' variable. Hence, we can drop this variable as it will not help with segmentation.\n",
    "* `Status`: This column was created just to get the `Family_Size` variable that contains the information about the Status. Hence, we can drop this variable.\n",
    "* We also need to drop categorical variables like `Education` and `Marital_Status`, `Kids`, `Kidhome`, and `Teenhome` as distance-based algorithms cannot use the default distance like Euclidean to find the distance between categorical and numerical variables.\n",
    "* We can also drop categorical variables like `AcceptedCmp1`, `AcceptedCmp2`, `AcceptedCmp3`, `AcceptedCmp4`, `AcceptedCmp5`, and `Response` for which we have create the variable `TotalAcceptedCmp` which is the aggregate of all these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ce76d3",
   "metadata": {
    "id": "f0ce76d3"
   },
   "outputs": [],
   "source": [
    "# Dropping all the irrelevant columns and storing in data_model\n",
    "data_model = data.drop(\n",
    "    columns=[\n",
    "        \"Year_Birth\",\n",
    "        \"Dt_Customer\",\n",
    "        \"day\",\n",
    "        \"Complain\",\n",
    "        \"Response\",\n",
    "        \"AcceptedCmp1\",\n",
    "        \"AcceptedCmp2\",\n",
    "        \"AcceptedCmp3\",\n",
    "        \"AcceptedCmp4\",\n",
    "        \"AcceptedCmp5\",\n",
    "        \"Marital_Status\",\n",
    "        \"Status\",\n",
    "        \"Kids\",\n",
    "        'Education',\n",
    "        'Kidhome',\n",
    "        'Teenhome', 'Income','Age', 'Family_Size'\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad26b8d",
   "metadata": {
    "id": "fad26b8d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the shape of new data \n",
    "_________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de55f99b",
   "metadata": {
    "id": "de55f99b"
   },
   "outputs": [],
   "source": [
    "# Check first five rows of new data\n",
    "_________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6baf94",
   "metadata": {
    "id": "7e6baf94"
   },
   "source": [
    "**Let's plot the correlation plot after we've removed the irrelevant variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611843da",
   "metadata": {
    "id": "611843da"
   },
   "outputs": [],
   "source": [
    "# Plot the correlation plot for new data\n",
    "_________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a113f41",
   "metadata": {
    "id": "7a113f41"
   },
   "source": [
    "**Observations and Insights:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f86dd84",
   "metadata": {
    "id": "7f86dd84"
   },
   "source": [
    "### Scaling the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754d65a4",
   "metadata": {
    "id": "754d65a4"
   },
   "source": [
    "**What is feature scaling?**\n",
    "\n",
    "Feature scaling is a class of statistical techniques that, as the name implies, scales the features of our data so that they all have a similar range. You'll understand better if we look at an example:\n",
    "\n",
    "If you have multiple independent variables like Age, Income, and Amount related variables, with their range as (18–100 Years), (25K–75K), and (100–200), respectively, feature scaling would help them all to be in the same range.\n",
    "\n",
    "**Why feature scaling is important in Unsupervised Learning?**\n",
    "\n",
    "Feature scaling is especially relevant in machine learning models that compute some sort of distance metric as we do in most clustering algorithms, for example, K-Means. \n",
    "\n",
    "So, scaling should be done to avoid the problem of one feature dominating over others because the unsupervised learning algorithm uses distance to find the similarity between data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f91b734",
   "metadata": {
    "id": "8f91b734"
   },
   "source": [
    "**Let's scale the data**\n",
    "\n",
    "**Standard Scaler**: StandardScaler standardizes a feature by subtracting the mean and then scaling to unit variance. Unit variance means dividing all the values by the standard deviation.\n",
    "\n",
    "![SC.png](attachment:SC.png)\n",
    "\n",
    "1. Data standardization is the process of rescaling the attributes so that they have a mean of 0 and a variance of 1.\n",
    "2. The ultimate goal to perform standardization is to bring down all the features to a common scale without distorting the differences in the range of the values.\n",
    "3. In sklearn.preprocessing.StandardScaler(), centering and scaling happen independently on each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d39752f",
   "metadata": {
    "id": "2d39752f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Applying standard scaler on new data\n",
    "scaler = _________                                                   # Initialize the Standard Scaler\n",
    "\n",
    "df_scaled = scaler.__________                                        # fit_transform the scaler function on new data\n",
    "\n",
    "df_scaled = pd.DataFrame(df_scaled, columns=data_model.columns)      # Converting the embeddings to a dataframe\n",
    "\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1a656f",
   "metadata": {
    "id": "9c1a656f"
   },
   "source": [
    "## **Applying T-SNE and PCA to the data to visualize the data distributed in 2 dimensions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0324acb",
   "metadata": {
    "id": "f0324acb"
   },
   "source": [
    "### **Applying T-SNE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c3539d",
   "metadata": {
    "id": "c2c3539d"
   },
   "outputs": [],
   "source": [
    "# Fitting T-SNE with number of components equal to 2 to visualize how data is distributed\n",
    "\n",
    "tsne = _____________        # Initializing T-SNE with number of component equal to 2, random_state=1, and perplexity=35\n",
    "\n",
    "data_air_pol_tsne = ___________                            # fit_transform T-SNE on new data\n",
    "\n",
    "data_air_pol_tsne = pd.DataFrame(data_air_pol_tsne, columns=[0, 1])           # Converting the embeddings to a dataframe\n",
    "\n",
    "plt.figure(figsize=(7, 7))                                                    # Scatter plot for two components\n",
    "\n",
    "sns.scatterplot(x=0, y=1, data=data_air_pol_tsne)                             # Plotting T-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5f30dc",
   "metadata": {
    "id": "2a5f30dc"
   },
   "source": [
    "**Observation and Insights:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f715ff",
   "metadata": {
    "id": "c4f715ff"
   },
   "source": [
    "### **Applying PCA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f028e30",
   "metadata": {
    "id": "8f028e30"
   },
   "source": [
    "**Think about it:**\n",
    "- Should we apply clustering algorithms on the current data or should we apply PCA on the data before applying clustering algorithms? How would this help?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132914a3",
   "metadata": {
    "id": "132914a3"
   },
   "source": [
    "When the variables used in clustering are highly correlated, it causes multicollinearity, which affects the clustering method and results in poor cluster profiling (or biased toward a few variables). PCA can be used to reduce the multicollinearity between the variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482ba0e6",
   "metadata": {
    "id": "482ba0e6"
   },
   "outputs": [],
   "source": [
    "# Defining the number of principal components to generate\n",
    "n = data_model.shape[1]                                        # Storing the number of variables in the data\n",
    "\n",
    "pca = _________________                                        # Initialize PCA with n_components = n and random_state=1\n",
    "\n",
    "data_pca = pd.DataFrame(pca.____________)                      # fit_transform PCA on the scaled data\n",
    "\n",
    "# The percentage of variance explained by each principal component is stored\n",
    "exp_var = pca.explained_variance_ratio_                     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0305f9e8",
   "metadata": {
    "id": "0305f9e8"
   },
   "source": [
    "**Let's plot the first two components and see how the data points are distributed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f408dbed",
   "metadata": {
    "id": "f408dbed"
   },
   "outputs": [],
   "source": [
    "# Scatter plot for two components using the dataframe data_pca\n",
    "____________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5856be29",
   "metadata": {
    "id": "5856be29"
   },
   "source": [
    "**Let's apply clustering algorithms on the data generated after applying PCA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55dd08b",
   "metadata": {
    "id": "f55dd08b"
   },
   "source": [
    "## **K-Means** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f055a8fe",
   "metadata": {
    "id": "f055a8fe"
   },
   "outputs": [],
   "source": [
    "distortions = []                                                  # Create an empty list\n",
    "\n",
    "K = range(2, 10)                                                  # Setting the K range from 2 to 10\n",
    "\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k,random_state=4)              # Initialize K-Means\n",
    "    kmeanModel.fit(data_pca)                                      # Fit K-Means on the data\n",
    "    distortions.append(kmeanModel.inertia_)                       # Append distortion values to the empty list created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a849a4",
   "metadata": {
    "id": "b2a849a4"
   },
   "outputs": [],
   "source": [
    "# Plotting the elbow plot\n",
    "plt.figure(figsize=(16, 8))                                            # Setting the plot size\n",
    "\n",
    "plt.plot(K, distortions, \"bx-\")                                        # Plotting the K on X-axis and distortions on y-axis\n",
    "\n",
    "plt.xlabel(\"k\")                                                        # Title of x-axis\n",
    "\n",
    "plt.ylabel(\"Distortion\")                                               # Title of y-axis\n",
    "\n",
    "plt.title(\"The Elbow Method showing the optimal k\")                    # Title of the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3857aa08",
   "metadata": {
    "id": "3857aa08"
   },
   "source": [
    "**In the above plot, the elbow is seen for K=3 and K=5 as there is some drop in distortion at K=3 and K=5.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfa1df7",
   "metadata": {
    "id": "edfa1df7"
   },
   "source": [
    "**Think About It:**\n",
    "\n",
    "- How do we determine the optimal K value when the elbows are observed at 2 or more K values from the elbow curve?\n",
    "- Which metric can be used to determine the final K value?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcc3d32",
   "metadata": {
    "id": "afcc3d32"
   },
   "source": [
    "**We can use the silhouette score as a metric for different K values to make a better decision about picking the number of clusters(K).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e55428",
   "metadata": {
    "id": "f9e55428"
   },
   "source": [
    "### **What is the silhouette score?**\n",
    "\n",
    "Silhouette score is one of the methods for evaluating the quality of clusters created using clustering algorithms such as K-Means. The silhouette score is a measure of how similar an object is to its cluster (cohesion) compared to other clusters (separation). Silhouette score has a range of [-1, 1].\n",
    "\n",
    "* Silhouette coefficients near +1 indicate that the clusters are dense and well separated, which is good.\n",
    "* Silhouette score near -1 indicates that those samples might have been assigned to the wrong cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0e5c3e",
   "metadata": {
    "id": "cb0e5c3e"
   },
   "source": [
    "**Finding silhouette score for each value of K**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3f65f3",
   "metadata": {
    "id": "6f3f65f3"
   },
   "outputs": [],
   "source": [
    "sil_score = []                                                             # Creating empty list\n",
    "cluster_list = range(3, 7)                                                 # Creating a range from 3 to 7\n",
    "for n_clusters in cluster_list:\n",
    "    \n",
    "    # Initialize K-Means with number of clusters equal to n_clusters and random_state=1\n",
    "    clusterer = _______________\n",
    "    \n",
    "    # Fit and predict on the pca data\n",
    "    preds = clusterer._________ \n",
    "    \n",
    "    # Calculate silhouette score - Hint: Use silhouette_score() function\n",
    "    score = ___________  \n",
    "    \n",
    "    # Append silhouette score to empty list created above\n",
    "    __________         \n",
    "    \n",
    "    # Print the silhouette score\n",
    "    print( \"For n_clusters = {}, the silhouette score is {})\".format(n_clusters, score))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccc59a8",
   "metadata": {
    "id": "3ccc59a8"
   },
   "source": [
    "**From the above silhouette scores, 3 appears to be a good value of K. So, let's build K-Means using K=3.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9f50a7",
   "metadata": {
    "id": "da9f50a7"
   },
   "source": [
    "### **Applying K-Means on data_pca**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed152db9",
   "metadata": {
    "id": "ed152db9"
   },
   "outputs": [],
   "source": [
    "kmeans = _____________                                # Initialize the K-Means algorithm with 3 clusters and random_state=1\n",
    "\n",
    "kmeans.__________                                     # Fitting on the data_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4823f6",
   "metadata": {
    "id": "ba4823f6"
   },
   "outputs": [],
   "source": [
    "data_pca[\"K_means_segments_3\"] = kmeans.labels_                    # Adding K-Means cluster labels to the data_pca data\n",
    "\n",
    "data[\"K_means_segments_3\"] = kmeans.labels_                        # Adding K-Means cluster labels to the whole data\n",
    "\n",
    "data_model[\"K_means_segments_3\"] = kmeans.labels_                  # Adding K-Means cluster labels to data_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b79c56",
   "metadata": {
    "id": "95b79c56"
   },
   "outputs": [],
   "source": [
    "# Let's check the distribution\n",
    "data_model[\"K_means_segments_3\"]._________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39115d43",
   "metadata": {
    "id": "39115d43"
   },
   "source": [
    "**Let's visualize the clusters using PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3847ec74",
   "metadata": {
    "id": "3847ec74"
   },
   "outputs": [],
   "source": [
    "# Function to visualize PCA data with clusters formed\n",
    "def PCA_PLOT(X, Y, PCA, cluster):\n",
    "    sns.scatterplot(x=X, y=1, data=PCA, hue=cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9f9cd8",
   "metadata": {
    "id": "af9f9cd8"
   },
   "outputs": [],
   "source": [
    "PCA_PLOT(0, 1, data_pca, \"K_means_segments_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7058a4a7",
   "metadata": {
    "id": "7058a4a7"
   },
   "source": [
    "**Observations and Insights:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddfd387",
   "metadata": {
    "id": "9ddfd387"
   },
   "source": [
    "### **Cluster Profiling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaa0291",
   "metadata": {
    "id": "eaaa0291"
   },
   "outputs": [],
   "source": [
    "# Taking the cluster-wise mean of all the variables. Hint: First groupby 'data' by 'K_means_segments_3' and then find mean\n",
    "cluster_profile_KMeans_3 = _____________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518ed9ca",
   "metadata": {
    "id": "518ed9ca",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Highlighting the maximum average value among all the clusters for each of the variables\n",
    "cluster_profile_KMeans_3.style.highlight_max(color=\"lightgreen\", axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f3b350",
   "metadata": {
    "id": "04f3b350"
   },
   "source": [
    "**Observations and Insights:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81af8109",
   "metadata": {
    "id": "81af8109"
   },
   "source": [
    "**Let us create a boxplot for each of the variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689b06e6",
   "metadata": {
    "id": "689b06e6"
   },
   "outputs": [],
   "source": [
    "# Columns to use in boxplot\n",
    "col_for_box = ['Income','Kidhome','Teenhome','Recency','MntWines','MntFruits','MntMeatProducts','MntFishProducts','MntSweetProducts','MntGoldProds','NumDealsPurchases','NumWebPurchases','NumCatalogPurchases','NumStorePurchases','NumWebVisitsMonth','Complain','Age','Family_Size','Expenses','NumTotalPurchases','Engaged_in_days','TotalAcceptedCmp','AmountPerPurchase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b312bb5",
   "metadata": {
    "id": "1b312bb5"
   },
   "outputs": [],
   "source": [
    "# Creating boxplot for each of the variables\n",
    "all_col = col_for_box\n",
    "\n",
    "plt.figure(figsize = (30, 50))\n",
    "\n",
    "for i, variable in enumerate(all_col):\n",
    "    plt.subplot(6, 4, i + 1)\n",
    "    \n",
    "    sns.__________(y=data[variable], x=data['K_means_segments_3'],showmeans=True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.title(variable)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380bb5d4",
   "metadata": {
    "id": "380bb5d4"
   },
   "source": [
    "### **Characteristics of each cluster:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd1a949",
   "metadata": {
    "id": "5fd1a949"
   },
   "source": [
    "**Cluster 0:__________**\n",
    "\n",
    "**Summary for cluster 0:_______________** \n",
    "\n",
    "**Cluster 1:_______________**\n",
    "\n",
    "**Summary for cluster 1:_______________**\n",
    "\n",
    "\n",
    "\n",
    "**Cluster 2:_______________** \n",
    "\n",
    "**Summary for cluster 2:_______________**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f8b3d0",
   "metadata": {
    "id": "08f8b3d0"
   },
   "source": [
    "**Think About It:**\n",
    "- Are the K-Means profiles with K=3 providing any deep insights into customer purchasing behavior or which channels they are using?\n",
    "- What is the next step to get more meaningful insights? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a8e859",
   "metadata": {
    "id": "b5a8e859"
   },
   "source": [
    "We can see from the above profiles that K=3 segments the customers into High, Medium and Low-income customers, and we are not getting deep insights into different types of customers. So, let's try to build K=5 (which has another elbow in the Elbow curve) and see if we can get better cluster profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ed9bba",
   "metadata": {
    "id": "00ed9bba"
   },
   "outputs": [],
   "source": [
    "# Dropping labels we got from K=3 since we will be using PCA data for prediction\n",
    "# Drop K_means_segments_3. Hint: Use axis=1 and inplace=True\n",
    "data_pca._______\n",
    "data._______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79fb95f",
   "metadata": {
    "id": "f79fb95f"
   },
   "source": [
    "**Let's build K-Means using K=5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3548bf89",
   "metadata": {
    "id": "3548bf89"
   },
   "outputs": [],
   "source": [
    "# Fit the K-Means algorithm using number of cluster as 5 and random_state=0 on data_pca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0d6ff7",
   "metadata": {
    "id": "2e0d6ff7"
   },
   "outputs": [],
   "source": [
    "# Add K-Means cluster labels to data_pca\n",
    "\n",
    "# Add K-Means cluster labels to whole data\n",
    "\n",
    "# Add K-Means cluster labels to data_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498c9bf2",
   "metadata": {
    "id": "498c9bf2"
   },
   "outputs": [],
   "source": [
    "# Let's check the distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8177be",
   "metadata": {
    "id": "7e8177be"
   },
   "source": [
    "**Let's visualize the clusters using PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd8acff",
   "metadata": {
    "id": "abd8acff"
   },
   "outputs": [],
   "source": [
    "# Hint: Use PCA_PLOT function created above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65ce959",
   "metadata": {
    "id": "f65ce959"
   },
   "source": [
    "### **Cluster Profiling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7793cc2",
   "metadata": {
    "id": "f7793cc2"
   },
   "outputs": [],
   "source": [
    "# Take the cluster-wise mean of all the variables. Hint: First groupby 'data' by cluster labels column and then find mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c714ce5c",
   "metadata": {
    "id": "c714ce5c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Highlight the maximum average value among all the clusters for each of the variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2964b3",
   "metadata": {
    "id": "0b2964b3"
   },
   "source": [
    "**Let's plot the boxplot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c233433",
   "metadata": {
    "id": "9c233433"
   },
   "outputs": [],
   "source": [
    "# Create boxplot for each of the variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d533fc",
   "metadata": {
    "id": "00d533fc"
   },
   "source": [
    "### **Characteristics of each cluster**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc42d2d3",
   "metadata": {
    "id": "cc42d2d3"
   },
   "source": [
    "**Cluster 0:__________**\n",
    "\n",
    "**Summary for cluster 0:_______________** \n",
    "\n",
    "**Cluster 1:_______________**\n",
    "\n",
    "**Summary for cluster 1:_______________**\n",
    "\n",
    "\n",
    "**Cluster 2:_______________** \n",
    "\n",
    "**Summary for cluster 2:_______________**\n",
    "\n",
    "**Cluster 3:_______________** \n",
    "\n",
    "**Summary for cluster 3:_______________**\n",
    "\n",
    "**Cluster 4:_______________** \n",
    "\n",
    "**Summary for cluster 4:_______________**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c296e7",
   "metadata": {
    "id": "28c296e7"
   },
   "outputs": [],
   "source": [
    "# Dropping labels we got from K-Means since we will be using PCA data for prediction\n",
    "# Hint: Use axis=1 and inplace=True\n",
    "data_pca._____________\n",
    "data.____________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d943ef79",
   "metadata": {
    "id": "d943ef79"
   },
   "source": [
    "From the above profiles, K=5 provides more interesting insights about customer's purchasing behavior and preferred channels for purchasing products. We can also see that the High, Medium and Low income groups have different age groups and preferences, which was not evident in K=3. So, **we can choose K=5.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e598e6d5",
   "metadata": {
    "id": "e598e6d5"
   },
   "source": [
    "## **K-Medoids**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1369fd9",
   "metadata": {
    "id": "a1369fd9"
   },
   "source": [
    "**Let's find the silhouette score for K=5 in K-Medoids**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5860e7bb",
   "metadata": {
    "id": "5860e7bb"
   },
   "outputs": [],
   "source": [
    "kmedo = ____________           # Initializing K-Medoids with number of clusters as 5 and random_state=1\n",
    "\n",
    "preds = ___________            # Fit and predict K-Medoids using data_pca\n",
    "\n",
    "score = ____________           # Calculate the silhouette score\n",
    "\n",
    "print(score)                   # Print the score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4c3698",
   "metadata": {
    "id": "fa4c3698"
   },
   "source": [
    "**Observations and Insights:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a3695d",
   "metadata": {
    "id": "50a3695d"
   },
   "outputs": [],
   "source": [
    "# Predicting on data_pca and ddding K-Medoids cluster labels to the whole data\n",
    "\n",
    "# Predicting on data_pca and ddding K-Medoids cluster labels to data_model\n",
    "\n",
    "# Predicting on data_pca and ddding K-Medoids cluster labels to data_pca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edebcc76",
   "metadata": {
    "id": "edebcc76"
   },
   "outputs": [],
   "source": [
    "# Let's check the distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93f8763",
   "metadata": {
    "id": "d93f8763"
   },
   "source": [
    "**Let's visualize the clusters using PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f87f4d",
   "metadata": {
    "id": "93f87f4d"
   },
   "outputs": [],
   "source": [
    "# Hint: Use PCA_PLOT function created above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5c9271",
   "metadata": {
    "id": "ef5c9271"
   },
   "source": [
    "### **Cluster Profiling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466c8f31",
   "metadata": {
    "id": "466c8f31"
   },
   "outputs": [],
   "source": [
    "# Take the cluster-wise mean of all the variables. Hint: First group 'data' by cluster labels column and then find mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a594f4da",
   "metadata": {
    "id": "a594f4da"
   },
   "outputs": [],
   "source": [
    "# Highlight the maximum average value among all the clusters for each of the variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ea3508",
   "metadata": {
    "id": "34ea3508"
   },
   "source": [
    "**Let's plot the boxplot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eac924",
   "metadata": {
    "id": "23eac924"
   },
   "outputs": [],
   "source": [
    "# Create boxplot for each of the variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7b8741",
   "metadata": {
    "id": "6b7b8741"
   },
   "source": [
    "### **Characteristics of each cluster**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d17f83a",
   "metadata": {
    "id": "9d17f83a"
   },
   "source": [
    "**Cluster 0:__________**\n",
    "\n",
    "**Summary for cluster 0:_______________** \n",
    "\n",
    "**Cluster 1:_______________**\n",
    "\n",
    "**Summary for cluster 1:_______________**\n",
    "\n",
    "\n",
    "**Cluster 2:_______________** \n",
    "\n",
    "**Summary for cluster 2:_______________**\n",
    "\n",
    "**Cluster 3:_______________** \n",
    "\n",
    "**Summary for cluster 3:_______________**\n",
    "\n",
    "**Cluster 4:_______________** \n",
    "\n",
    "**Summary for cluster 4:_______________**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ea4ad5",
   "metadata": {
    "id": "62ea4ad5"
   },
   "outputs": [],
   "source": [
    "# Dropping labels we got from K-Medoids since we will be using PCA data for prediction\n",
    "# Hint: Use axis=1 and inplace=True\n",
    "data_pca._____________\n",
    "data.____________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424dd661",
   "metadata": {
    "id": "424dd661"
   },
   "source": [
    "## **Hierarchical Clustering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020ceab2",
   "metadata": {
    "id": "020ceab2"
   },
   "source": [
    "Let's find the Cophenetic correlation for different distances with different linkage methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb02ef61",
   "metadata": {
    "id": "eb02ef61"
   },
   "source": [
    "### **What is a Cophenetic correlation?**\n",
    "\n",
    "The cophenetic correlation coefficient is a correlation coefficient between the cophenetic distances(Dendrogramic distance) obtained from the tree, and the original distances used to construct the tree. It is a measure of how faithfully a dendrogram preserves the pairwise distances between the original unmodeled data points. \n",
    "\n",
    "The cophenetic distance between two observations is represented in a dendrogram by the height of the link at which those two observations are first joined. That height is the distance between the two subclusters that are merged by that link.\n",
    "\n",
    "Cophenetic correlation is the way to compare two or more dendrograms. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c25567",
   "metadata": {
    "id": "26c25567"
   },
   "source": [
    "**Let's calculate Cophenetic correlation for each of the distance metrics with each of the linkage methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c1c251",
   "metadata": {
    "id": "17c1c251"
   },
   "outputs": [],
   "source": [
    "# list of distance metrics\n",
    "distance_metrics = [\"euclidean\", \"chebyshev\", \"mahalanobis\", \"cityblock\"]\n",
    "\n",
    "# list of linkage methods\n",
    "linkage_methods = [\"single\", \"complete\", \"average\"]\n",
    "\n",
    "high_cophenet_corr = 0                                                 # Creating a variable by assigning 0 to it\n",
    "high_dm_lm = [0, 0]                                                    # Creating a list by assigning 0's to it\n",
    "\n",
    "for dm in distance_metrics:\n",
    "    for lm in linkage_methods:\n",
    "        Z = linkage(data_pca, metric=dm, method=lm)                    # Applying different linkages with different distance on data_pca\n",
    "        c, coph_dists = cophenet(Z, pdist(data_pca))                   # Calculating cophenetic correlation\n",
    "        print(\n",
    "            \"Cophenetic correlation for {} distance and {} linkage is {}.\".format(\n",
    "                dm.capitalize(), lm, c\n",
    "            )\n",
    "        )\n",
    "        if high_cophenet_corr < c:                                     # Checking if cophenetic correlation is higher than previous score\n",
    "            high_cophenet_corr = c                                     # Appending to high_cophenet_corr list if it is higher\n",
    "            high_dm_lm[0] = dm                                         # Appending its corresponding distance\n",
    "            high_dm_lm[1] = lm                                         # Appending its corresponding method or linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f0c62e",
   "metadata": {
    "id": "e7f0c62e"
   },
   "outputs": [],
   "source": [
    "# Printing the combination of distance metric and linkage method with the highest cophenetic correlation\n",
    "print(\n",
    "    \"Highest cophenetic correlation is {}, which is obtained with {} distance and {} linkage.\".format(\n",
    "        high_cophenet_corr, high_dm_lm[0].capitalize(), high_dm_lm[1]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8c31bb",
   "metadata": {
    "id": "8c8c31bb"
   },
   "source": [
    "**Let's have a look at the dendrograms for different linkages with `Cityblock distance`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a1aa81",
   "metadata": {
    "id": "d5a1aa81"
   },
   "outputs": [],
   "source": [
    "# List of linkage methods\n",
    "linkage_methods = [\"single\", \"complete\", \"average\"]\n",
    "\n",
    "# Lists to save results of cophenetic correlation calculation\n",
    "compare_cols = [\"Linkage\", \"Cophenetic Coefficient\"]\n",
    "\n",
    "# To create a subplot image\n",
    "fig, axs = plt.subplots(len(linkage_methods), 1, figsize=(15, 30))            # Setting the plot size\n",
    "\n",
    "# We will enumerate through the list of linkage methods above\n",
    "# For each linkage method, we will plot the dendrogram and calculate the cophenetic correlation\n",
    "for i, method in enumerate(linkage_methods):\n",
    "    Z = linkage(data_pca, metric=\"Cityblock\", method=method)                  # Measures the distances between two clusters\n",
    "\n",
    "    dendrogram(Z, ax=axs[i])\n",
    "    axs[i].set_title(f\"Dendrogram ({method.capitalize()} Linkage)\")           # Title of dendrogram\n",
    "\n",
    "    coph_corr, coph_dist = cophenet(Z, pdist(data_pca))                       # Finding cophenetic correlation for different linkages with city block distance\n",
    "    axs[i].annotate(\n",
    "        f\"Cophenetic\\nCorrelation\\n{coph_corr:0.2f}\",\n",
    "        (0.80, 0.80),\n",
    "        xycoords=\"axes fraction\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc8787a",
   "metadata": {
    "id": "1cc8787a"
   },
   "source": [
    "**Observations and Insights:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d8fbb6",
   "metadata": {
    "id": "35d8fbb6"
   },
   "source": [
    "**Think about it:**\n",
    "\n",
    "- Can we clearly decide the number of clusters based on where to cut the dendrogram horizontally?\n",
    "- What is the next step in obtaining number of clusters based on the dendrogram?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d39f40",
   "metadata": {
    "id": "13d39f40"
   },
   "source": [
    "**Let's have a look at the dendrograms for different linkages with `Chebyshev distance`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26690933",
   "metadata": {
    "id": "26690933"
   },
   "outputs": [],
   "source": [
    "# Plot the dendrogram for Chebyshev distance with linkages single, complete and average. \n",
    "# Hint: Use Chebyshev distance as the metric in the linkage() function \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dc3441",
   "metadata": {
    "id": "91dc3441"
   },
   "source": [
    "**Observations and Insights:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29addff5",
   "metadata": {
    "id": "29addff5"
   },
   "source": [
    "**Let's have a look at the dendrograms for different linkages with Mahalanobis distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ba170a",
   "metadata": {
    "id": "60ba170a"
   },
   "outputs": [],
   "source": [
    "# Plot the dendrogram for Mahalanobis distance with linkages single, complete and average. \n",
    "# Hint: Use Mahalanobis distance as the metric in the linkage() function \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc24b3c",
   "metadata": {
    "id": "ebc24b3c"
   },
   "source": [
    "**Observations and Insights:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8d76b8",
   "metadata": {
    "id": "ad8d76b8"
   },
   "source": [
    "**Let's have a look at the dendrograms for different linkages with Euclidean distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5453b59e",
   "metadata": {
    "id": "5453b59e"
   },
   "outputs": [],
   "source": [
    "# Plot the dendrogram for Euclidean distance with linkages single, complete, average and ward. \n",
    "# Hint: Use Euclidean distance as the metric in the linkage() function \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ac3177",
   "metadata": {
    "id": "24ac3177"
   },
   "source": [
    "**Think about it:**\n",
    "\n",
    "- Are there any distinct clusters in any of the dendrograms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017f94b8",
   "metadata": {
    "id": "017f94b8"
   },
   "source": [
    "**Observations and Insights:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0caef1d",
   "metadata": {
    "id": "b0caef1d"
   },
   "outputs": [],
   "source": [
    "# Initialize Agglomerative Clustering with affinity (distance) as Euclidean, linkage as 'Ward' with clusters=3\n",
    "HCmodel = AgglomerativeClustering(n_clusters=______, affinity=______, linkage=______,) \n",
    "\n",
    "# Fit on data_pca\n",
    "HCmodel.__________                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e893ba",
   "metadata": {
    "id": "65e893ba"
   },
   "outputs": [],
   "source": [
    "# Add Agglomerative Clustering cluster labels to data_pca\n",
    "\n",
    "# Add Agglomerative Clustering cluster labels to the whole data\n",
    "\n",
    "# Add Agglomerative Clustering cluster labels to data_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ec7d8c",
   "metadata": {
    "id": "18ec7d8c"
   },
   "outputs": [],
   "source": [
    "# Let's check the distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fab854",
   "metadata": {
    "id": "e2fab854"
   },
   "source": [
    "**Let's visualize the clusters using PCA.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d799565c",
   "metadata": {
    "id": "d799565c"
   },
   "outputs": [],
   "source": [
    "# Hint: Use PCA_PLOT function created above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87baf95",
   "metadata": {
    "id": "c87baf95"
   },
   "source": [
    "### **Cluster Profiling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a329ff4d",
   "metadata": {
    "id": "a329ff4d"
   },
   "outputs": [],
   "source": [
    "# Take the cluster-wise mean of all the variables. Hint: First group 'data' by cluster labels column and then find mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f934b1",
   "metadata": {
    "id": "a7f934b1"
   },
   "outputs": [],
   "source": [
    "# Highlight the maximum average value among all the clusters for each of the variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52260d8a",
   "metadata": {
    "id": "52260d8a"
   },
   "source": [
    "**Let's plot the boxplot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a60a12e",
   "metadata": {
    "id": "4a60a12e"
   },
   "outputs": [],
   "source": [
    "# Create boxplot for each of the variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237ce2e9",
   "metadata": {
    "id": "237ce2e9"
   },
   "source": [
    "### **Characteristics of each cluster**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3534a662",
   "metadata": {
    "id": "3534a662"
   },
   "source": [
    "**Cluster 0:__________**\n",
    "\n",
    "**Summary for cluster 0:_______________** \n",
    "\n",
    "**Cluster 1:_______________**\n",
    "\n",
    "**Summary for cluster 1:_______________**\n",
    "\n",
    "\n",
    "**Cluster 2:_______________** \n",
    "\n",
    "**Summary for cluster 2:_______________**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b8aa74",
   "metadata": {
    "id": "51b8aa74"
   },
   "source": [
    "**Observations and Insights:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37179889",
   "metadata": {
    "id": "37179889"
   },
   "outputs": [],
   "source": [
    "# Dropping labels we got from Agglomerative Clustering since we will be using PCA data for prediction\n",
    "# Hint: Use axis=1 and inplace=True\n",
    "data_pca._____________\n",
    "data.____________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e425520",
   "metadata": {
    "id": "8e425520"
   },
   "source": [
    "## **DBSCAN**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c941735",
   "metadata": {
    "id": "5c941735"
   },
   "source": [
    "DBSCAN is a very powerful algorithm for finding high-density clusters, but the problem is determining the best set of hyperparameters to use with it. It includes two hyperparameters, `eps`, and `min samples`.\n",
    "\n",
    "Since it is an unsupervised algorithm, you have no control over it, unlike a supervised learning algorithm, which allows you to test your algorithm on a validation set. The approach we can follow is basically trying out a bunch of different combinations of values and finding the silhouette score for each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480b6c72",
   "metadata": {
    "id": "480b6c72"
   },
   "outputs": [],
   "source": [
    "# Initializing lists\n",
    "eps_value = [2,3]                       # Taking random eps value\n",
    "min_sample_values = [6,20]              # Taking random min_sample value\n",
    "\n",
    "# Creating a dictionary for each of the values in eps_value with min_sample_values\n",
    "res = {eps_value[i]: min_sample_values for i in range(len(eps_value))}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c5e7e6",
   "metadata": {
    "id": "c0c5e7e6"
   },
   "outputs": [],
   "source": [
    "# Finding the silhouette_score for each of the combinations\n",
    "high_silhouette_avg = 0                                               # Assigning 0 to the high_silhouette_avg variable\n",
    "high_i_j = [0, 0]                                                     # Assigning 0's to the high_i_j list\n",
    "key = res.keys()                                                      # Assigning dictionary keys to a variable called key\n",
    "for i in key:\n",
    "    z = res[i]                                                        # Assigning dictionary values of each i to z\n",
    "    for j in z:\n",
    "        db = DBSCAN(eps=i, min_samples=j).fit(data_pca)               # Applying DBSCAN to each of the combination in dictionary\n",
    "        core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "        core_samples_mask[db.core_sample_indices_] = True\n",
    "        labels = db.labels_\n",
    "        silhouette_avg = silhouette_score(data_pca, labels)           # Finding silhouette score \n",
    "        print( \n",
    "            \"For eps value =\" + str(i),\n",
    "            \"For min sample =\" + str(j),\n",
    "            \"The average silhoutte_score is :\",\n",
    "            silhouette_avg,                                          # Printing the silhouette score for each of the combinations\n",
    "        )\n",
    "        if high_silhouette_avg < silhouette_avg:                     # If the silhouette score is greater than 0 or the previous score, it will get appended to the high_silhouette_avg list with its combination of i and j              \n",
    "            high_i_j[0] = i\n",
    "            high_i_j[1] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ce94a1",
   "metadata": {
    "id": "50ce94a1"
   },
   "outputs": [],
   "source": [
    "# Printing the highest silhouette score\n",
    "print(\"Highest_silhoutte_avg is {} for eps = {} and min sample = {}\".format(high_silhouette_avg, high_i_j[0], high_i_j[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80247dce",
   "metadata": {
    "id": "80247dce"
   },
   "source": [
    "**Now, let's apply DBSCAN using the hyperparameter values we have received above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d118ef9e",
   "metadata": {
    "id": "d118ef9e"
   },
   "outputs": [],
   "source": [
    "# Apply DBSCAN using the above hyperparameter values\n",
    "dbs = _____________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa911be2",
   "metadata": {
    "id": "fa911be2"
   },
   "outputs": [],
   "source": [
    "# fit_predict on data_pca and add DBSCAN cluster labels to the whole data\n",
    "\n",
    "# fit_predict on data_pca and add DBSCAN cluster labels to data_model\n",
    "\n",
    "# fit_predict on data_pca and add DBSCAN cluster labels to data_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47699c3e",
   "metadata": {
    "id": "47699c3e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's check the distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a311c74",
   "metadata": {
    "id": "8a311c74"
   },
   "source": [
    "**Let's visualize the clusters using PCA.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426e7f93",
   "metadata": {
    "id": "426e7f93"
   },
   "outputs": [],
   "source": [
    "# Hint: Use PCA_PLOT function created above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a80374c",
   "metadata": {
    "id": "5a80374c"
   },
   "source": [
    "**Observations and Insights:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de39ed10",
   "metadata": {
    "id": "de39ed10"
   },
   "source": [
    "**Think about it:**\n",
    "\n",
    "- Changing the eps and min sample values will result in different DBSCAN results? Can we try more value for eps and min_sample?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06334fb7",
   "metadata": {
    "id": "06334fb7"
   },
   "source": [
    "**Note:** You can experiment with different eps and min_sample values to see if DBSCAN produces good distribution and cluster profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0a7075",
   "metadata": {
    "id": "1f0a7075"
   },
   "outputs": [],
   "source": [
    "# Dropping labels we got from DBSCAN since we will be using PCA data for prediction\n",
    "# Hint: Use axis=1 and inplace=True\n",
    "data_pca._____________\n",
    "data.____________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30613efa",
   "metadata": {
    "id": "30613efa"
   },
   "source": [
    "## **Gaussian Mixture Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fca82b0",
   "metadata": {
    "id": "8fca82b0"
   },
   "source": [
    "**Let's find the silhouette score for K=5 in Gaussian Mixture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4ade2e",
   "metadata": {
    "id": "9d4ade2e"
   },
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(_______) # Initialize Gaussian Mixture Model with number of clusters as 5 and random_state=1\n",
    "\n",
    "preds = ___________            # Fit and predict Gaussian Mixture Model using data_pca\n",
    "\n",
    "score = ____________           # Calculate the silhouette score\n",
    "\n",
    "print(score)                   # Print the score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0c8dc6",
   "metadata": {
    "id": "3e0c8dc6"
   },
   "source": [
    "**Observations and Insights:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b4f14f",
   "metadata": {
    "id": "a1b4f14f"
   },
   "outputs": [],
   "source": [
    "# Predicting on data_pca and add Gaussian Mixture Model cluster labels to the whole data\n",
    "\n",
    "# Predicting on data_pca and add Gaussian Mixture Model cluster labels to data_model\n",
    "\n",
    "# Predicting on data_pca and add Gaussian Mixture Model cluster labels to data_pca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1f8dde",
   "metadata": {
    "id": "2c1f8dde"
   },
   "outputs": [],
   "source": [
    "# Let's check the distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642ebb6b",
   "metadata": {
    "id": "642ebb6b"
   },
   "source": [
    "**Let's visualize the clusters using PCA.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52969ce",
   "metadata": {
    "id": "c52969ce"
   },
   "outputs": [],
   "source": [
    "# Hint: Use PCA_PLOT function created above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e536e1",
   "metadata": {
    "id": "31e536e1"
   },
   "source": [
    "### **Cluster Profiling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2fb20e",
   "metadata": {
    "id": "3a2fb20e"
   },
   "outputs": [],
   "source": [
    "# Take the cluster-wise mean of all the variables. Hint: First group 'data' by cluster labels column and then find mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280c66a7",
   "metadata": {
    "id": "280c66a7"
   },
   "outputs": [],
   "source": [
    "# Highlight the maximum average value among all the clusters for each of the variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a2d324",
   "metadata": {
    "id": "72a2d324"
   },
   "source": [
    "**Let's plot the boxplot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695c58f8",
   "metadata": {
    "id": "695c58f8"
   },
   "outputs": [],
   "source": [
    "# Create boxplot for each of the variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10442989",
   "metadata": {
    "id": "10442989"
   },
   "source": [
    "### **Characteristics of each cluster**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f776b12",
   "metadata": {
    "id": "0f776b12"
   },
   "source": [
    "**Cluster 0:__________**\n",
    "\n",
    "**Summary for cluster 0:_______________** \n",
    "\n",
    "**Cluster 1:_______________**\n",
    "\n",
    "**Summary for cluster 1:_______________**\n",
    "\n",
    "\n",
    "**Cluster 2:_______________** \n",
    "\n",
    "**Summary for cluster 2:_______________**\n",
    "\n",
    "**Cluster 3:_______________** \n",
    "\n",
    "**Summary for cluster 3:_______________**\n",
    "\n",
    "**Cluster 4:_______________** \n",
    "\n",
    "**Summary for cluster 4:_______________**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73367782",
   "metadata": {
    "id": "73367782"
   },
   "source": [
    "## **Conclusion and Recommendations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "N5BT7Ocwqf5x",
   "metadata": {
    "id": "N5BT7Ocwqf5x"
   },
   "source": [
    "**1. Comparison of various techniques and their relative performance based on chosen Metric (Measure of success)**:\n",
    "- How do different techniques perform? Which one is performing relatively better? Is there scope to improve the performance further?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wjc6vTcoqp6v",
   "metadata": {
    "id": "wjc6vTcoqp6v"
   },
   "source": [
    "**2. Refined insights**:\n",
    "- What are the most meaningful insights from the data relevant to the problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hK6PMGUtoxVx",
   "metadata": {
    "id": "hK6PMGUtoxVx"
   },
   "source": [
    "**3. Proposal for the final solution design:** \n",
    "- What model do you propose to be adopted? Why is this the best solution to adopt?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
