{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bg-DvjFCyXSr"
   },
   "source": [
    "# **Facial Emotion Detection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYdEI31whyE-"
   },
   "source": [
    "## **Problem Definition**\n",
    "\n",
    "**The context:** Why is this problem important to solve?<br>\n",
    "**The objectives:** What is the intended goal?<br>\n",
    "**The key questions:** What are the key questions that need to be answered?<br>\n",
    "**The problem formulation:** What are we trying to solve using data science?\n",
    "\n",
    "\n",
    "\n",
    "## **About the dataset**\n",
    "\n",
    "The data set consists of 3 folders, i.e., 'test', 'train', and 'validation'. \n",
    "Each of these folders has four subfolders:\n",
    "\n",
    "**‘happy’**: Images of people who have happy facial expressions.<br>\n",
    "**‘sad’**: Images of people with sad or upset facial expressions.<br>\n",
    "**‘surprise’**: Images of people who have shocked or surprised facial expressions.<br>\n",
    "**‘neutral’**: Images of people showing no prominent emotion in their facial expression at all.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "entENKtxK-g-"
   },
   "source": [
    "## **Important Notes**\n",
    "\n",
    "- This notebook can be considered a guide to refer to while solving the problem. The evaluation will be as per the Rubric shared for each Milestone. Unlike previous courses, it does not follow the pattern of the graded questions in different sections. This notebook would give you a direction on what steps need to be taken to get a feasible solution to the problem. Please note that this is just one way of doing this. **There can be other 'creative' ways to solve the problem, and we encourage you to feel free and explore them as an 'optional' exercise**. \n",
    "\n",
    "- In the notebook, there are markdown cells called Observations and Insights. It is a good practice to provide observations and extract insights from the outputs.\n",
    "\n",
    "- The naming convention for different variables can vary. **Please consider the code provided in this notebook as a sample code.**\n",
    "\n",
    "- All the outputs in the notebook are just for reference and can be different if you follow a different approach.\n",
    "\n",
    "- There are sections called **Think About It** in the notebook that will help you get a better understanding of the reasoning behind a particular technique/step. Interested learners can take alternative approaches if they want to explore different techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDM89XHyCxrA"
   },
   "source": [
    "## **Mounting the Drive**\n",
    "\n",
    "**NOTE:**  Please use Google Colab from your browser for this notebook. **Google.colab is NOT a library that can be downloaded locally on your device.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JQi_degJC3dm",
    "outputId": "70feb0a1-5cab-4be2-e92f-b1dbc89a3e3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Mounting the drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UC8-yLUUCcWh"
   },
   "source": [
    "## **Importing the Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "30fd2144"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Importing Deep Learning Libraries\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D, LeakyReLU\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCqJk2XpCnJi"
   },
   "source": [
    "### **Let us load the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_syvBdMlDTsr"
   },
   "source": [
    "**Note:** \n",
    "- You must download the dataset from the link provided on Olympus and upload the same on your Google drive before executing the code in the next cell.\n",
    "- In case of any error, please make sure that the path of the file is correct as the path may be different for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sMfr4tK04C0o"
   },
   "outputs": [],
   "source": [
    "# Storing the path of the data file from the Google drive\n",
    "path = '/content/drive/MyDrive/Facial_emotion_images.zip'\n",
    "\n",
    "# The data is provided as a zip file so we need to extract the files from the zip file\n",
    "with zipfile.ZipFile(path, 'r') as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4e89d1c7"
   },
   "outputs": [],
   "source": [
    "picture_size = 48\n",
    "folder_path = \"Facial_emotion_images/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YpkYTD705Eky"
   },
   "source": [
    "## **Visualizing our Classes**\n",
    "\n",
    "Let's look at our classes. \n",
    "\n",
    "**Write down your observation for each class. What do you think can be a unique feature of each emotion, that separates it from the remaining classes?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mb59IxA35WF-"
   },
   "source": [
    "### **Happy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6f89821c"
   },
   "outputs": [],
   "source": [
    "expression = 'happy'\n",
    "\n",
    "plt.figure(figsize= (8,8))\n",
    "for i in range(1, 10, 1):\n",
    "    plt.subplot(3, 3, i)\n",
    "\n",
    "    img = load_img(folder_path + \"train/\" + expression + \"/\" +\n",
    "                  os.listdir(folder_path + \"train/\" + expression)[i], target_size = (picture_size, picture_size))\n",
    "    plt.imshow(img)   \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWYioRFM5jMJ"
   },
   "source": [
    "**Observations and Insights:__**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28ZzJwIK6HTH"
   },
   "source": [
    "### **Sad**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4n0oXebe6b0g"
   },
   "outputs": [],
   "source": [
    "# Write your code to visualize images from the class 'sad'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5BpviSLK6mLO"
   },
   "source": [
    "**Observations and Insights:__**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8D3nRj8x7gjK"
   },
   "source": [
    "### **Neutral**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M9bRAog_7qPl"
   },
   "outputs": [],
   "source": [
    "# Write your code to visualize images from the class 'neutral'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AjvfkXFE70Wa"
   },
   "source": [
    "**Observations and Insights:__**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "avUJfLm08cgt"
   },
   "source": [
    "### **Surprised**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tDrkuxNm8mWE"
   },
   "outputs": [],
   "source": [
    "# Write your code to visualize images from the class 'surprise'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTnBsUNH_djf"
   },
   "source": [
    "**Observations and Insights:__**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZMfyOH4-YSp"
   },
   "source": [
    "## **Checking Distribution of Classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m7rCOsTl-HbZ"
   },
   "outputs": [],
   "source": [
    "# Getting count of images in each folder within our training path\n",
    "num_happy = len(os.listdir(folder_path + \"train/happy\"))\n",
    "print(\"Number of images in the class 'happy':   \", num_happy)\n",
    "\n",
    "num_sad = # Write the code to get the number of training images from the class 'sad'.\n",
    "\n",
    "num_neutral = # Write the code to get the number of training images from the class 'neutral'.\n",
    "\n",
    "num_surprise = # Write the code to get the number of training images from the class 'surprise'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WSa0LTav_wEQ"
   },
   "outputs": [],
   "source": [
    "# Code to plot histogram\n",
    "plt.figure(figsize = (10, 5))\n",
    "\n",
    "data = {'Happy': num_happy, 'Sad': num_sad, 'Neutral': num_neutral, 'Surprise' : num_surprise}\n",
    "\n",
    "df = pd.Series(data)\n",
    "\n",
    "plt.bar(range(len(df)), df.values, align = 'center')\n",
    "\n",
    "plt.xticks(range(len(df)), df.index.values, size = 'small')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "reZRpnmv8qPL"
   },
   "source": [
    "**Observations and Insights:__**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfJnIxXC80uZ"
   },
   "source": [
    "**Think About It:** \n",
    "* Are the classes equally distributed? If not, do you think the imbalance is too high? Will it be a problem as we progress?\n",
    "* Are there any Exploratory Data Analysis tasks that we can do here? Would they provide any meaningful insights?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7NKTPgdEsgt"
   },
   "source": [
    "## **Creating our Data Loaders**\n",
    "\n",
    "In this section, we are creating data loaders that we will use as inputs to our Neural Network. A sample of the required code has been given with respect to the training data. Please create the data loaders for validation and test set accordingly.\n",
    "\n",
    "**You have two options for the color_mode. You can set it to color_mode = 'rgb' or color_mode = 'grayscale'. You will need to try out both and see for yourself which one gives better performance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d97fee2d"
   },
   "outputs": [],
   "source": [
    "batch_size  = 32\n",
    "img_size = 48\n",
    "\n",
    "datagen_train = ImageDataGenerator(horizontal_flip = True,\n",
    "                                    brightness_range=(0.,2.),\n",
    "                                    rescale=1./255,\n",
    "                                    shear_range=0.3)\n",
    "\n",
    "train_set = datagen_train.flow_from_directory(folder_path + \"train\",\n",
    "                                              target_size = (img_size, img_size),\n",
    "                                              color_mode = # Provide your chosen color_mode here ,\n",
    "                                              batch_size = batch_size,\n",
    "                                              class_mode = 'categorical',\n",
    "                                              shuffle = True)\n",
    "\n",
    "\n",
    "datagen_validation = # Write your code here\n",
    "\n",
    "validation_set = # Write your code here\n",
    "\n",
    "\n",
    "datagen_test = # Write your code here\n",
    "\n",
    "test_set = # Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_qGpQC3q1avy"
   },
   "source": [
    "## **Model Building**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSl8GqRdAcGq"
   },
   "source": [
    "**Think About It:**\n",
    "* Are Convolutional Neural Networks the right approach? Should we have gone with Artificial Neural Networks instead? \n",
    "* What are the advantages of CNNs over ANNs and are they applicable here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0feec0a7"
   },
   "source": [
    "### **Creating the Base Neural Network**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5XDAnGWJJSc"
   },
   "source": [
    "Our Base Neural network will be a fairly simple model architecture.\n",
    "\n",
    "* We want our Base Neural Network architecture to have 3 convolutional blocks.\n",
    "* Each convolutional block must contain one Conv2D layer followed by a maxpooling layer and one Dropout layer. We can play around with the dropout ratio.\n",
    "* Add first Conv2D layer with **64 filters** and a **kernel size of 2**. Use the 'same' padding and provide the **input_shape = (48, 48, 3) if you are using 'rgb' color mode in your dataloader or else input shape = (48, 48, 1) if you're using 'grayscale' colormode**. Use **'relu' activation**.\n",
    "* Add MaxPooling2D layer with **pool size = 2**.\n",
    "* Add a Dropout layer with a dropout ratio of 0.2.\n",
    "* Add a second Conv2D layer with **32 filters** and a **kernel size of 2**. Use the **'same' padding** and **'relu' activation.**\n",
    "* Follow this up with a similar Maxpooling2D layer like above and a Dropout layer with 0.2 Dropout ratio to complete your second Convolutional Block.\n",
    "* Add a third Conv2D layer with **32 filters** and a **kernel size of 2**. Use the **'same' padding** and **'relu' activation.** Once again, follow it up with a Maxpooling2D layer and a Dropout layer to complete your third Convolutional block.\n",
    "* After adding your convolutional blocks, add your Flatten layer.\n",
    "* Add your first Dense layer with **512 neurons**. Use **'relu' activation function**.\n",
    "* Add a Dropout layer with dropout ratio of 0.4.\n",
    "* Add your final Dense Layer with 4 neurons and **'softmax' activation function**\n",
    "* Print your model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "151077af"
   },
   "outputs": [],
   "source": [
    "# Initializing a Sequential Model\n",
    "model1 = Sequential()\n",
    "\n",
    "# Add the first Convolutional block\n",
    "\n",
    "# Add the second Convolutional block\n",
    "\n",
    "# Add the third Convolutional block\n",
    "\n",
    "# Add the Flatten layer\n",
    "\n",
    "# Add the first Dense layer\n",
    "\n",
    "# Add the Final layer\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vgOwCHZxqAlG"
   },
   "source": [
    "### **Compiling and Training the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "87b29701"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./model1.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss',\n",
    "                          min_delta = 0,\n",
    "                          patience = 3,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True\n",
    "                          )\n",
    "\n",
    "reduce_learningrate = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                              factor = 0.2,\n",
    "                              patience = 3,\n",
    "                              verbose = 1,\n",
    "                              min_delta = 0.0001)\n",
    "\n",
    "callbacks_list = [early_stopping, checkpoint, reduce_learningrate]\n",
    "\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IccRagCP9iNb"
   },
   "outputs": [],
   "source": [
    "# Write your code to compile your model1. Use categorical crossentropy as your loss function, Adam Optimizer with 0.001 learning rate, and set your metrics to 'accuracy'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "37b93a84"
   },
   "outputs": [],
   "source": [
    "# Write your code to fit your model1. Use train_set as your training data and validation_set as your validation data. Train your model for 20 epochs.\n",
    "\n",
    "history = model1.fit(_________)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CR2yf3zH7uje"
   },
   "source": [
    "### **Evaluating the Model on the Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gffvQXr-70Hm"
   },
   "outputs": [],
   "source": [
    "# Write your code to evaluate your model on test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SoqluqR-RMbk"
   },
   "source": [
    "**Observations and Insights:__**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12efb6c8"
   },
   "source": [
    "### **Creating the second Convolutional Neural Network**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ypwtou8Zp5EH"
   },
   "source": [
    "In the second Neural network, we will add a few more Convolutional blocks. We will also use Batch Normalization layers.\n",
    "\n",
    "* This time, each Convolutional block will have 1 Conv2D layer, followed by a BatchNormalization, LeakuRelU, and a MaxPooling2D layer. We are not adding any Dropout layer this time.\n",
    "* Add first Conv2D layer with **256 filters** and a **kernel size of 2**. Use the 'same' padding and provide the **input_shape = (48, 48, 3) if you are using 'rgb' color mode in your dataloader or else input shape = (48, 48, 1) if you're using 'grayscale' colormode**. Use **'relu' activation**.\n",
    "* Add your BatchNormalization layer followed by a LeakyRelU layer with Leaky ReLU parameter of **0.1**\n",
    "* Add MaxPooling2D layer with **pool size = 2**.\n",
    "* Add a second Conv2D layer with **128 filters** and a **kernel size of 2**. Use the **'same' padding** and **'relu' activation.**\n",
    "* Follow this up with a similar BatchNormalization, LeakyRelU, and Maxpooling2D layer like above to complete your second Convolutional Block.\n",
    "* Add a third Conv2D layer with **64 filters** and a **kernel size of 2**. Use the **'same' padding** and **'relu' activation.** Once again, follow it up with a BatchNormalization, LeakyRelU, and Maxpooling2D layer to complete your third Convolutional block.\n",
    "* Add a fourth block, with the Conv2D layer having **32 filters**.\n",
    "* After adding your convolutional blocks, add your Flatten layer.\n",
    "* Add your first Dense layer with **512 neurons**. Use **'relu' activation function**.\n",
    "* Add the second Dense Layer with **128 neurons** and use **'relu' activation** function.\n",
    "* Add your final Dense Layer with 4 neurons and **'softmax' activation function**\n",
    "* Print your model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7887b475"
   },
   "outputs": [],
   "source": [
    "# Creating sequential model\n",
    "model2 = Sequential()\n",
    " \n",
    "# Add the first Convolutional block\n",
    "\n",
    "# Add the second Convolutional block\n",
    "\n",
    "# Add the third Convolutional block\n",
    "\n",
    "# Add the fourth Convolutional block\n",
    "\n",
    "# Add the Flatten layer\n",
    "\n",
    "# Adding the Dense layers\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2d7wYiTk5uW"
   },
   "source": [
    "### **Compiling and Training the Model**\n",
    "\n",
    "**Hint:** Take reference from the code we used in the previous model for Compiling and Training the Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5f79add6"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./model2.h5\", monitor='val_loss', verbose = 1, save_best_only = True, mode = 'max')\n",
    "\n",
    "early_stopping = ________ # Write your code here. You may play around with the hyperparameters if you wish.\n",
    "\n",
    "reduce_learningrate = _________ # Write your code here. You may play around with the hyperparameters if you wish.\n",
    "\n",
    "callbacks_list = [early_stopping, checkpoint, reduce_learningrate]\n",
    "\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kovNtiI5_w09"
   },
   "outputs": [],
   "source": [
    "# Write your code to compile your model2. Use categorical crossentropy as the loss function, Adam Optimizer with 0.001 learning rate, and set metrics as 'accuracy'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e2c3d909"
   },
   "outputs": [],
   "source": [
    "history = # Write your code to fit your model2. Use train_set as the training data and validation_set as the validation data. Train your model for 20 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VeiN9vSy744e"
   },
   "source": [
    "### **Evaluating the Model on the Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YBNeB-Em7xBy"
   },
   "outputs": [],
   "source": [
    "# Write your code to evaluate model's test performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MstKA9Op8XOA"
   },
   "source": [
    "**Observations and Insights:__**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1LQ64iTsSH0"
   },
   "source": [
    "## **Think About It:**\n",
    "\n",
    "* Did the models have a satisfactory performance? If not, then what are the possible reasons?\n",
    "* Which Color mode showed better overall performance? What are the possible reasons? Do you think having 'rgb' color mode is needed because the images are already black and white?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "boQi7epI3Lsu"
   },
   "source": [
    "## **Transfer Learning Architectures**\n",
    "\n",
    "In this section, we will create several Transfer Learning architectures. For the pre-trained models, we will select three popular architectures namely, VGG16, ResNet v2, and Efficient Net. The difference between these architectures and the previous architectures is that these will require 3 input channels while the earlier ones worked on 'grayscale' images. Therefore, we need to create new DataLoaders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tusr9gcYDpTT"
   },
   "source": [
    "### **Creating our Data Loaders for Transfer Learning Architectures**\n",
    "\n",
    "In this section, we are creating data loaders that we will use as inputs to our Neural Network. We will have to go with color_mode = 'rgb' as this is the required format for the transfer learning architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jDSH1sXqDpTT"
   },
   "outputs": [],
   "source": [
    "batch_size  = 32\n",
    "img_size = 48\n",
    "\n",
    "datagen_train = ImageDataGenerator(horizontal_flip = True,\n",
    "                                    brightness_range = (0., 2.),\n",
    "                                    rescale = 1./255,\n",
    "                                    shear_range = 0.3)\n",
    "\n",
    "train_set = datagen_train.flow_from_directory(folder_path + \"train\",\n",
    "                                              target_size = (img_size, img_size),\n",
    "                                              color_mode = 'rgb',\n",
    "                                              batch_size = batch_size,\n",
    "                                              class_mode = 'categorical',\n",
    "                                              classes = ['happy', 'sad', 'neutral', 'surprise'],\n",
    "                                              shuffle = True)\n",
    "\n",
    "datagen_validation = # Write your code here\n",
    "\n",
    "validation_set = # Write your code here\n",
    "\n",
    "datagen_test = # Write your code here\n",
    "\n",
    "test_set = # Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vaUYQdkf7pDG"
   },
   "source": [
    "## **VGG16 Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ThCSNrWC4HW0"
   },
   "source": [
    "### **Importing the VGG16 Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7c83c83e"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "vgg = VGG16(include_top = False, weights = 'imagenet', input_shape = (48, 48, 3))\n",
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X76HMyZX4edM"
   },
   "source": [
    "### **Model Building**\n",
    "\n",
    "* In this model, we will import till the **'block5_pool'** layer of the VGG16 model. You can scroll down in the model summary and look for 'block5_pool'. You can choose any other layer as well.\n",
    "* Then we will add a Flatten layer, which receives the output of the 'block5_pool' layer as its input.\n",
    "* We will add a few Dense layers and use 'relu' activation function on them.\n",
    "* You may use Dropout and BatchNormalization layers as well.\n",
    "* Then we will add our last dense layer, which must have 4 neurons and a 'softmax' activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8b123bc6"
   },
   "outputs": [],
   "source": [
    "transfer_layer = vgg.get_layer('block5_pool')\n",
    "vgg.trainable = False\n",
    "\n",
    "# Add classification layers on top of it  \n",
    "____________\n",
    "\n",
    "# Flattenning the output from the 3rd block of the VGG16 model\n",
    "x = Flatten()(transfer_layer.output)\n",
    "\n",
    "# Adding a Dense layer with 256 neurons\n",
    "x = Dense(256, activation = 'relu')(x)\n",
    "\n",
    "# Add a Dense Layer with 128 neurons\n",
    "____________\n",
    "\n",
    "# Add a DropOut layer with Drop out ratio of 0.3\n",
    "____________\n",
    "\n",
    "# Add a Dense Layer with 64 neurons\n",
    "____________\n",
    "\n",
    "# Add a Batch Normalization layer\n",
    "____________\n",
    "\n",
    "# Adding the final dense layer with 4 neurons and use 'softmax' activation\n",
    "pred = Dense(4, activation='softmax')(x)\n",
    "\n",
    "vggmodel = Model(vgg.input, pred) # Initializing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6vK7u7w8GsM"
   },
   "source": [
    "### **Compiling and Training the VGG16 Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "86b249f1"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./vggmodel.h5\", monitor = 'val_loss', verbose = 1, save_best_only = True, mode = 'max')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss',\n",
    "                          min_delta = 0,\n",
    "                          patience = 3,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True\n",
    "                          )\n",
    "\n",
    "reduce_learningrate = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                              factor = 0.2,\n",
    "                              patience = 3,\n",
    "                              verbose = 1,\n",
    "                              min_delta = 0.0001)\n",
    "\n",
    "callbacks_list = [early_stopping, checkpoint, reduce_learningrate]\n",
    "\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0PN6ghMOGGgf"
   },
   "outputs": [],
   "source": [
    "# Write your code to compile the vggmodel. Use categorical crossentropy as the loss function, Adam Optimizer with 0.001 learning rate, and set metrics to 'accuracy'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "893285ee"
   },
   "outputs": [],
   "source": [
    "history = # Write your code to fit your model. Use train_set as the training data and validation_set as the validation data. Train the model for 20 epochs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Un-19jPckK07"
   },
   "source": [
    "### **Evaluating the VGG16 model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t6Y_bSLCkcvr"
   },
   "outputs": [],
   "source": [
    "# Write your code to evaluate model performance on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tW6kPSky59Gv"
   },
   "source": [
    "**Think About It:**\n",
    "\n",
    "- What do you infer from the general trend in the training performance? \n",
    "- Is the training accuracy consistently improving? \n",
    "- Is the validation accuracy also improving similarly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YuTi6OAx8q_r"
   },
   "source": [
    "**Observations and Insights:__**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AfC2Kx0v7Sa1"
   },
   "source": [
    "**Note: You can even go back and build your own architecture on top of the VGG16 Transfer layer and see if you can improve the performance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E0Mew4Cc7u7k"
   },
   "source": [
    "## **ResNet V2 Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "568a5c9a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.applications as ap\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "Resnet = ap.ResNet101(include_top = False, weights = \"imagenet\", input_shape=(48,48,3))\n",
    "Resnet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ay4RedCQlL4O"
   },
   "source": [
    "### **Model Building**\n",
    "\n",
    "* In this model, we will import till the **'conv5_block3_add'** layer of the ResNet model. You can scroll down in the model summary and look for 'conv5_block3_add'. You can choose any other layer as well.\n",
    "* Then we will add a Flatten layer, which receives the output of the 'conv5_block3_add' layer as its input.\n",
    "* We will add a few Dense layers and use 'relu' activation function on them.\n",
    "* You may use Dropout and BatchNormalization layers as well.\n",
    "* Then we will add our last dense layer, which must have 4 neurons and a 'softmax' activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "911d3335"
   },
   "outputs": [],
   "source": [
    "transfer_layer_Resnet = Resnet.get_layer('conv5_block3_add')\n",
    "Resnet.trainable=False\n",
    "\n",
    "# Add classification layers on top of it\n",
    "____________\n",
    "\n",
    "# Flattenning the output from the 3rd block of the VGG16 model\n",
    "x = Flatten()(transfer_layer_Resnet.output)\n",
    "\n",
    "# Add a Dense layer with 256 neurons\n",
    "x = Dense(256, activation = 'relu')(x)\n",
    "\n",
    "# Add a Dense Layer with 128 neurons\n",
    "____________\n",
    "\n",
    "# Add a DropOut layer with Drop out ratio of 0.3\n",
    "____________\n",
    "\n",
    "# Add a Dense Layer with 64 neurons\n",
    "____________\n",
    "\n",
    "# Add a Batch Normalization layer\n",
    "____________\n",
    "\n",
    "# Add the final dense layer with 4 neurons and use a 'softmax' activation\n",
    "pred = Dense(4, activation = 'softmax')(x)\n",
    "\n",
    "resnetmodel = Model(vgg.input, pred) # Initializing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tmtcd1ZElpJy"
   },
   "source": [
    "### **Compiling and Training the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fe959789"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./Resnetmodel.h5\", monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max')\n",
    "\n",
    "early_stopping = _________  # Write your code here. You may play around with the hyperparameters if you wish.\n",
    "\n",
    "\n",
    "reduce_learningrate = _________ # Write your code here. You may play around with the hyperparameters if you wish.\n",
    "\n",
    "\n",
    "callbacks_list = [early_stopping, checkpoint, reduce_learningrate]\n",
    "\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "641VUEtvGaLW"
   },
   "outputs": [],
   "source": [
    "# Write your code to compile your resnetmodel. Use categorical crossentropy as your loss function, Adam Optimizer with 0.001 learning rate, and set your metrics to 'accuracy'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mBZRmTFLIRtS"
   },
   "outputs": [],
   "source": [
    "history = # Write your code to fit your model. Use train_set as your training data and validation_set as your validation data. Train your model for 20 epochs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "McHEzBlhxw39"
   },
   "source": [
    "### **Evaluating the ResNet Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IEl6IQf0xwci"
   },
   "outputs": [],
   "source": [
    "# Write your code to evaluate model performance on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3htKZRdomiOY"
   },
   "source": [
    "**Observations and Insights:__**\n",
    "\n",
    "**Note: You can even go back and build your own architecture on top of the ResNet Transfer layer and see if you can improve the performance.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FmnDG4ZbncoR"
   },
   "source": [
    "## **EfficientNet Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "613c7a71"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.applications as ap\n",
    "from tensorflow.keras import Model\n",
    "EfficientNet = ap.EfficientNetV2B2(include_top=False,weights=\"imagenet\", input_shape= (48, 48, 3))\n",
    "\n",
    "EfficientNet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6kDNE8pVngqC"
   },
   "source": [
    "### **Model Building**\n",
    "\n",
    "**Build your own Architecture on top of the transfer layer. Be sure to have a Flatten layer after your transfer layer and also make sure you have 4 neurons and softmax activation function in your last dense layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2b27a6e1"
   },
   "outputs": [],
   "source": [
    "transfer_layer_EfficientNet = EfficientNet.get_layer('block6e_expand_activation')\n",
    "EfficientNet.trainable = False\n",
    "\n",
    "# Add your Flatten layer.\n",
    "__________\n",
    "\n",
    "# Add your Dense layers and/or BatchNormalization and Dropout layers\n",
    "__________\n",
    "\n",
    "# Add your final Dense layer with 4 neurons and softmax activation function.\n",
    "__________\n",
    "\n",
    "Efficientnetmodel = Model(EfficientNet.input, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVv4Df_In32Y"
   },
   "source": [
    "### **Compiling and Training the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dc326cd3"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./Efficientnetmodel.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "early_stopping = _________  # Write your code here. You may play around with the hyperparameters if you wish.\n",
    "\n",
    "reduce_learningrate = _________  # Write your code here. You may play around with the hyperparameters if you wish.\n",
    "\n",
    "callbacks_list = [early_stopping,checkpoint,reduce_learningrate]\n",
    "\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U13gspW8I-e3"
   },
   "outputs": [],
   "source": [
    "# Write your code to compile your Efficientnetmodel. Use categorical crossentropy as your loss function, Adam Optimizer with 0.001 learning rate, and set your metrics to 'accuracy'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Doy0fkOwIew_"
   },
   "outputs": [],
   "source": [
    "history = # Write your code to fit your model. Use train_set as your training data and validation_set as your validation data. Train your model for 20 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xjrzYpgoQnN"
   },
   "source": [
    "### **Evaluating the EfficientnetNet Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WJVFenvnoQnN"
   },
   "outputs": [],
   "source": [
    "# Write your code to evaluate the model performance on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWlk14FOoQnN"
   },
   "source": [
    "**Observations and Insights:__**\n",
    "\n",
    "**Note: You can even go back and build your own architecture on top of the VGG16 Transfer layer and see if you can improve the performance.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fk6QAcv5odNF"
   },
   "source": [
    "**Think About It:**\n",
    "\n",
    "* What is your overall performance of these Transfer Learning Architectures? Can we draw a comparison of these models' performances. Are we satisfied with the accuracies that we have received?\n",
    "* Do you think our issue lies with 'rgb' color_mode?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EH3atQP8q_v"
   },
   "source": [
    "Now that we have tried multiple pre-trained models, let's build a complex CNN architecture and see if we can get better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjKlBaZDpWoV"
   },
   "source": [
    "## **Building a Complex Neural Network Architecture**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-bMFUj3Fpe75"
   },
   "source": [
    "In this section, we will build a more complex Convolutional Neural Network Model that has close to as many parameters as we had in our Transfer Learning Models. However, we will have only 1 input channel for our input images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejGfyYSbtx-F"
   },
   "source": [
    "## **Creating our Data Loaders**\n",
    "\n",
    "In this section, we are creating data loaders which we will use as inputs to the more Complicated Convolutional Neural Network. We will go ahead with color_mode = 'grayscale'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xj1hM5_ttx-F"
   },
   "outputs": [],
   "source": [
    "batch_size  = 32\n",
    "img_size = 48\n",
    "\n",
    "datagen_train = ImageDataGenerator(horizontal_flip = True,\n",
    "                                    brightness_range = (0., 2.),\n",
    "                                    rescale = 1./255,\n",
    "                                    shear_range = 0.3)\n",
    "\n",
    "train_set = datagen_train.flow_from_directory(folder_path + \"train\",\n",
    "                                              target_size = (img_size, img_size),\n",
    "                                              color_mode = 'grayscale',\n",
    "                                              batch_size = batch_size,\n",
    "                                              class_mode = 'categorical',\n",
    "                                              classes = ['happy', 'sad', 'neutral', 'surprise'],\n",
    "                                              shuffle = True)\n",
    "\n",
    "\n",
    "datagen_validation = # Write your code here\n",
    "\n",
    "validation_set = # Write your code here\n",
    "\n",
    "datagen_test = # Write your code here\n",
    "\n",
    "test_set = # Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ft5U6f1Wie2R"
   },
   "source": [
    "### **Model Building**\n",
    "\n",
    "* In this network, we plan to have 5 Convolutional Blocks\n",
    "* Add first Conv2D layer with **64 filters** and a **kernel size of 2**. Use the 'same' padding and provide the **input shape = (48, 48, 1)**. Use **'relu' activation**.\n",
    "* Add your BatchNormalization layer followed by a LeakyRelU layer with Leaky ReLU parameter of **0.1**\n",
    "* Add MaxPooling2D layer with **pool size = 2**.\n",
    "* Add a Dropout layer with a Dropout Ratio of **0.2**. This completes the first Convolutional block.\n",
    "* Add a second Conv2D layer with **128 filters** and a **kernel size of 2**. Use the **'same' padding** and **'relu' activation.**\n",
    "* Follow this up with a similar BatchNormalization, LeakyRelU, Maxpooling2D, and Dropout layer like above to complete your second Convolutional Block.\n",
    "* Add a third Conv2D layer with **512 filters** and a **kernel size of 2**. Use the **'same' padding** and **'relu' activation.** Once again, follow it up with a BatchNormalization, LeakyRelU, Maxpooling2D, and Dropout layer to complete your third Convolutional block.\n",
    "* Add a fourth block, with the Conv2D layer having **512 filters**.\n",
    "* Add the fifth block, having **128 filters**.\n",
    "* Then add your Flatten layer, followed by your Dense layers.\n",
    "* Add your first Dense layer with **256 neurons** followed by a BatchNormalization layer, a **'relu'** Activation, and a Dropout layer. This forms your first Fully Connected block\n",
    "* Add your second Dense layer with **512 neurons**, again followed by a BatchNormalization layer, **relu** activation, and a Dropout layer.\n",
    "* Add your final Dense layer with 4 neurons.\n",
    "* Compile your model with the optimizer of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "37f9194d"
   },
   "outputs": [],
   "source": [
    "no_of_classes = 4\n",
    "\n",
    "model3 = Sequential()\n",
    "\n",
    "# Add 1st CNN Block\n",
    "____________\n",
    "\n",
    "# Add 2nd CNN Block\n",
    "____________\n",
    "\n",
    "# Add 3rd CNN Block\n",
    "____________\n",
    "\n",
    "# Add 4th CNN Block\n",
    "____________\n",
    "\n",
    "# Add 5th CNN Block\n",
    "____________\n",
    "\n",
    "model3.add(Flatten())\n",
    "\n",
    "# First fully connected layer\n",
    "____________\n",
    "\n",
    "# Second fully connected layer\n",
    "____________\n",
    "\n",
    "model3.add(Dense(no_of_classes, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyc0B--hwTHS"
   },
   "source": [
    "### **Compiling and Training the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0edabf52"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "epochs = 35\n",
    "\n",
    "steps_per_epoch = train_set.n//train_set.batch_size\n",
    "validation_steps = validation_set.n//validation_set.batch_size\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model3.h5\", monitor = 'val_accuracy',\n",
    "                            save_weights_only = True, model = 'max', verbose = 1)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 2, min_lr = 0.0001 , model = 'auto')\n",
    "\n",
    "callbacks = [checkpoint, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IYDJwZWmKSK6"
   },
   "outputs": [],
   "source": [
    "# Write your code to compile your model3. Use categorical crossentropy as the loss function, Adam Optimizer with 0.003 learning rate, and set metrics to 'accuracy'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_tB9HX5sKjUL"
   },
   "outputs": [],
   "source": [
    "history = # Write your code to fit your model. Use train_set as the training data and validation_set as the validation data. Train your model for 35 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbAqrAQQVjIR"
   },
   "source": [
    "### **Evaluating the Model on Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uO26AYRuVm7F"
   },
   "outputs": [],
   "source": [
    "# Write your code to evaluate the model performance on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81uYGSmHwxfD"
   },
   "source": [
    "**Observations and Insights:__**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNWc6agwxJ_z"
   },
   "source": [
    "### **Plotting the Confusion Matrix for the chosen final model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SFTRyIk-yjoQ"
   },
   "outputs": [],
   "source": [
    "# Plot the confusion matrix and generate a classification report for the model\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "test_set = datagen_test.flow_from_directory(folder_path + \"test\",\n",
    "                                                              target_size = (img_size,img_size),\n",
    "                                                              color_mode = 'grayscale',\n",
    "                                                              batch_size = 128,\n",
    "                                                              class_mode = 'categorical',\n",
    "                                                              classes = ['happy', 'sad', 'neutral', 'surprise'],\n",
    "                                                              shuffle = True) \n",
    "test_images, test_labels = next(test_set)\n",
    "\n",
    "# Write the name of your chosen model in the blank\n",
    "pred = ________.predict(test_images)\n",
    "pred = np.argmax(pred, axis = 1) \n",
    "y_true = np.argmax(test_labels, axis = 1)\n",
    "\n",
    "# Printing the classification report\n",
    "_____________\n",
    "\n",
    "# Plotting the heatmap using confusion matrix\n",
    "cm = confusion_matrix(y_true, pred)\n",
    "plt.figure(figsize = (8, 5))\n",
    "sns.heatmap(cm, annot = True,  fmt = '.0f', xticklabels = ['happy', 'sad', 'neutral', 'surprise'], yticklabels = ['happy', 'sad', 'neutral', 'surprise'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGgvpOrP8q_x"
   },
   "source": [
    "**Observations and Insights:__**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6s_baiF_KllW"
   },
   "source": [
    "## **Conclusion:____________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MEZPA_mN0tUo"
   },
   "source": [
    "### **Insights**\n",
    "\n",
    "### **Refined insights**:\n",
    "- What are the most meaningful insights from the data relevant to the problem?\n",
    "\n",
    "### **Comparison of various techniques and their relative performance**:\n",
    "- How do different techniques perform? Which one is performing relatively better? Is there scope to improve the performance further?\n",
    "\n",
    "### **Proposal for the final solution design**:\n",
    "- What model do you propose to be adopted? Why is this the best solution to adopt?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
