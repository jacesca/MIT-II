{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75c79da8",
   "metadata": {
    "id": "75c79da8"
   },
   "source": [
    "# Recommendation Systems Practice Project: Book Recommendation\n",
    "\n",
    "---------------\n",
    "## **Context**\n",
    "---------------\n",
    "\n",
    "Over 3.5 billion people use the internet for a variety of reasons. Online retail sales are expected to grow steadily in the coming years. One of the most important requirements of E-commerce portals is a book recommendation for ease of reading and referencing. A book recommendation system is a type of recommendation system in which the reader is recommended similar books based on his or her interests.\n",
    "\n",
    "Book Recommendation Systems are used by the vast majority of E-commerce businesses such as Amazon, Barnes and Noble, Flipkart, Goodreads, and other online retailers to recommend books that customers may be tempted to buy based on their preferences. This feature can assist in increasing shopping value while reducing shopping time. Logical recommendations not only assist customers in making purchases but also increase total sales value.\n",
    "\n",
    "-----------------\n",
    "## **Objective**\n",
    "-----------------\n",
    "\n",
    "In this case study, we will build three types of recommendation systems: \n",
    "- **Knowledge/Rank Based recommendation system**\n",
    "- **Similarity-Based Collaborative filtering**\n",
    "- **Matrix Factorization Based Collaborative Filtering**\n",
    "\n",
    "\n",
    "-----------------\n",
    "## **Dataset**\n",
    "-----------------\n",
    "\n",
    "The **ratings** dataset contains the following attributes: \n",
    "- user-Id: Unique ID for each user\n",
    "- ISBN: International Standard Book Number. Books are identified by their respective ISBN\n",
    "- Book-rating: Rating for each book expressed on a scale from 0-10\n",
    "\n",
    "We will also use the **books** dataset to obtain book titles and other information. It contains the following attributes:\n",
    "- ISBN: International Standard Book Number\n",
    "- Book-title: Title of the book\n",
    "- Book-author: Name of the author\n",
    "- Year-of-Publication: Publication Year\n",
    "- Publisher: Name of the publisher of the book\n",
    "- Image-Url-S: Small image of the book (Amazon link)\n",
    "- Image-Url-M: Medium size image of the book (Amazon link)\n",
    "- Image-Url-L: Large size image of the book (Amazon link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704735f2",
   "metadata": {},
   "source": [
    "Sometimes, the installation of the surprise library, which is used to build recommendation systems, faces issues in Jupyter. To avoid any issues, it is advised to use **Google Colab** for this project.\n",
    "\n",
    "Let's start by mounting the Google drive on Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "INp4A0ot6kMr",
   "metadata": {
    "id": "INp4A0ot6kMr"
   },
   "outputs": [],
   "source": [
    "# Mount your drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uYVFkxnAQW7H",
   "metadata": {
    "id": "uYVFkxnAQW7H"
   },
   "outputs": [],
   "source": [
    "# Installing surprise library\n",
    "!pip install surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb8bac5",
   "metadata": {
    "id": "bcb8bac5"
   },
   "outputs": [],
   "source": [
    "# Basic python libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Python libraries for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For implementing matrix factorization based recommendation system\n",
    "from surprise.prediction_algorithms.matrix_factorization import SVD\n",
    "from collections import defaultdict\n",
    "\n",
    "# For implementing cross validation\n",
    "from surprise.model_selection import KFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462e60ca",
   "metadata": {
    "id": "462e60ca"
   },
   "source": [
    "## **Loading the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd91dbb8",
   "metadata": {
    "id": "fd91dbb8"
   },
   "outputs": [],
   "source": [
    "# Reading the datasets\n",
    "book = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/RS/Books.csv\")\n",
    "rating = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/RS/Ratings.csv\")\n",
    "user = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/RS/Users.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BLKe_h--SHJV",
   "metadata": {
    "id": "BLKe_h--SHJV"
   },
   "source": [
    "## **Exploring the ratings data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4EgS5SlCRhpZ",
   "metadata": {
    "id": "4EgS5SlCRhpZ"
   },
   "outputs": [],
   "source": [
    "rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df27e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "book.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c557756",
   "metadata": {
    "id": "7c557756"
   },
   "source": [
    "**Let's merge the 'rating' and 'book' datasets and then we can choose only the columns relevant to our task.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4o9nVcMFenLD",
   "metadata": {
    "id": "4o9nVcMFenLD"
   },
   "outputs": [],
   "source": [
    "df = pd.merge(rating, book.drop_duplicates(['ISBN']), on=\"ISBN\", how=\"left\")\n",
    "df.drop(['Image-URL-S','Image-URL-M','Image-URL-L'], axis =1, inplace = True)\n",
    "\n",
    "# Rename the column names of the dataframe\n",
    "df.rename(columns = {'User-ID':'user_id', 'ISBN':'book_id', \"Book-Rating\":\"rating\"}, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WKFfGqRkSNnR",
   "metadata": {
    "id": "WKFfGqRkSNnR"
   },
   "outputs": [],
   "source": [
    "# Checking the info of the data\n",
    "df.___________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w3rdN_PPWaRL",
   "metadata": {
    "id": "w3rdN_PPWaRL"
   },
   "source": [
    "**Observations:______**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kFzVA9sLeDiN",
   "metadata": {
    "id": "kFzVA9sLeDiN"
   },
   "outputs": [],
   "source": [
    "# Many book_id contains combination of letters & digits. So we will convert the column to type 'string'\n",
    "df['book_id']= df['book_id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "osSmweRhkpuI",
   "metadata": {
    "id": "osSmweRhkpuI"
   },
   "source": [
    "### **Checking the distribution of ratings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WquoXO0FSMxw",
   "metadata": {
    "id": "WquoXO0FSMxw"
   },
   "outputs": [],
   "source": [
    "# Distribution of ratings\n",
    "plt.figure(figsize = (12, 4))\n",
    "sns.countplot(_______________)\n",
    "\n",
    "plt.tick_params(labelsize = 10)\n",
    "plt.title(\"Distribution of Ratings \", fontsize = 10)\n",
    "plt.xlabel(\"Ratings\", fontsize = 10)\n",
    "plt.ylabel(\"Number of Ratings\", fontsize = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "R7qE93BxXOq8",
   "metadata": {
    "id": "R7qE93BxXOq8"
   },
   "source": [
    "**Observations:______**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g4Dze3BN_Rbf",
   "metadata": {
    "id": "g4Dze3BN_Rbf"
   },
   "source": [
    "### **Dropping rows with rating equal to 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uJrvV0iP_Zc2",
   "metadata": {
    "id": "uJrvV0iP_Zc2"
   },
   "outputs": [],
   "source": [
    "df.drop(df.index[df['rating'] == 0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eqri9zcemvEO",
   "metadata": {
    "id": "eqri9zcemvEO"
   },
   "outputs": [],
   "source": [
    "# Checking info of the data after removing entries with rating = 0 \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sf0zvqwe5ur7",
   "metadata": {
    "id": "sf0zvqwe5ur7"
   },
   "source": [
    "**Observations:______**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbb105a",
   "metadata": {},
   "source": [
    "Let's check the distribution of ratings again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VPM4ngailQmX",
   "metadata": {
    "id": "VPM4ngailQmX"
   },
   "source": [
    "### **Checking updated distribution of ratings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kb66wryT9qVF",
   "metadata": {
    "id": "kb66wryT9qVF"
   },
   "outputs": [],
   "source": [
    "# Distribution of ratings\n",
    "plt.figure(figsize = (12, 4))\n",
    "sns.countplot(______________)\n",
    "\n",
    "plt.tick_params(labelsize = 10)\n",
    "plt.title(\"Distribution of Ratings \", fontsize = 10)\n",
    "plt.xlabel(\"Ratings\", fontsize = 10)\n",
    "plt.ylabel(\"Number of Ratings\", fontsize = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-57mhIwdksgr",
   "metadata": {
    "id": "-57mhIwdksgr"
   },
   "source": [
    "**Observations:______**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "id6eLatCSM4N",
   "metadata": {
    "id": "id6eLatCSM4N"
   },
   "outputs": [],
   "source": [
    "# Finding the number of unique users\n",
    "# Remove _______ and complete the code\n",
    "\n",
    "df['user_id']._____________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a951080",
   "metadata": {
    "id": "8a951080"
   },
   "outputs": [],
   "source": [
    "# Finding the number of unique books\n",
    "\n",
    "# Remove _______ and complete the code\n",
    "df['book_id']._____________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Br8_JTxlXkor",
   "metadata": {
    "id": "Br8_JTxlXkor"
   },
   "source": [
    "**Observations:______**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MmKRLghiXOGU",
   "metadata": {
    "id": "MmKRLghiXOGU"
   },
   "outputs": [],
   "source": [
    "df.groupby(['user_id', 'book_id']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b063OhmXlxr",
   "metadata": {
    "id": "5b063OhmXlxr"
   },
   "outputs": [],
   "source": [
    "df.groupby(['user_id', 'book_id']).count()['rating'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1wCzbygSYjyu",
   "metadata": {
    "id": "1wCzbygSYjyu"
   },
   "source": [
    "**Observation:**\n",
    "- The **sum is equal to the total number of observations**, which implies that **there is only one interaction between a book and a user**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "A0nNz6WBZlDl",
   "metadata": {
    "id": "A0nNz6WBZlDl"
   },
   "source": [
    "#### Which book has the highest number of reviews / ratings in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ErNU3QI8Xl0T",
   "metadata": {
    "id": "ErNU3QI8Xl0T"
   },
   "outputs": [],
   "source": [
    "# Finding the most rated books in the dataset\n",
    "df['book_id']._________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bf7d60",
   "metadata": {},
   "source": [
    "**Observations:_____**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UgoO6MYuXl2g",
   "metadata": {
    "id": "UgoO6MYuXl2g"
   },
   "outputs": [],
   "source": [
    "# Plotting distributions of ratings for the most interacted book\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "\n",
    "df[df['book_id'] == _________]['rating'].value_counts().plot(kind='bar')  # Hint: Put the book_id in string format\n",
    "\n",
    "plt.xlabel('Rating')\n",
    "\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sIHzQxZWenov",
   "metadata": {
    "id": "sIHzQxZWenov"
   },
   "source": [
    "**Observations:______**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "r-_UHDi4enBb",
   "metadata": {
    "id": "r-_UHDi4enBb"
   },
   "outputs": [],
   "source": [
    "# Finding the user who interacted most\n",
    "df['user_id'].__________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oQwICkL2svvj",
   "metadata": {
    "id": "oQwICkL2svvj"
   },
   "source": [
    "**Observations:______**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f563b4",
   "metadata": {},
   "source": [
    "## **Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oyG2AtXiyO1m",
   "metadata": {
    "id": "oyG2AtXiyO1m"
   },
   "source": [
    "As this dataset is still quite large and has 433671 observations, it is not be computationally efficient to build a model using this. Moreover, there are many users who have only rated a few books and also there are also books which are rated by very less users. Hence we can reduce the dataset by considering certain Logical assumption.\n",
    "\n",
    "Here, We will be taking users who have given at least 50 rating, as we prefer to have some number of rating of a book and the book which has at least 10 rating, as when we shop online we prefer to have some number of rating of that product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0pnCxxsbXOJE",
   "metadata": {
    "id": "0pnCxxsbXOJE"
   },
   "outputs": [],
   "source": [
    "# Get the column containing the users\n",
    "users = df.user_id\n",
    "# Create a dictionary from users to find their number of books\n",
    "ratings_count = dict()\n",
    "for user in users:\n",
    "    # If we already have the user, just add 1 to their rating count\n",
    "    if user in ratings_count:\n",
    "        ratings_count[user] += 1\n",
    "    # Otherwise, set their rating count to 1\n",
    "    else:\n",
    "        ratings_count[user] = 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kJOHn3Ik02O8",
   "metadata": {
    "id": "kJOHn3Ik02O8"
   },
   "outputs": [],
   "source": [
    "# We want our users to have at least 50 ratings to be considered\n",
    "RATINGS_CUTOFF = 50\n",
    "remove_users = []\n",
    "for user, num_ratings in ratings_count.items():\n",
    "    if num_ratings < RATINGS_CUTOFF:\n",
    "        remove_users.append(user)\n",
    "df = df.loc[~df.user_id.isin(remove_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LIoNRnSP3cQQ",
   "metadata": {
    "id": "LIoNRnSP3cQQ"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8BWjYyO3lLG",
   "metadata": {
    "id": "d8BWjYyO3lLG"
   },
   "outputs": [],
   "source": [
    "# Get the column containing the books\n",
    "books = df.book_id\n",
    "# Create a dictionary from books to find their number of users\n",
    "ratings_count = dict()\n",
    "for book in books:\n",
    "    # If we already have the book, just add 1 to their rating count\n",
    "    if book in ratings_count:\n",
    "        _________________\n",
    "    # Otherwise, set their rating count to 1\n",
    "    else:\n",
    "        _________________   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QxoiWgKn02a1",
   "metadata": {
    "id": "QxoiWgKn02a1"
   },
   "outputs": [],
   "source": [
    "# We want our book to be interacted by at least 10 users to be considered\n",
    "RATINGS_CUTOFF = _____\n",
    "remove_books = []\n",
    "for book, num_ratings in _________:\n",
    "    if num_ratings < RATINGS_CUTOFF:\n",
    "        remove_books.______________\n",
    "df= df.loc[~df.book_id.isin(_______)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zoeqZNvf02rB",
   "metadata": {
    "id": "zoeqZNvf02rB"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4HD6qgHT4Ivu",
   "metadata": {
    "id": "4HD6qgHT4Ivu"
   },
   "source": [
    "### **Distribution of the user-books interactions in the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_DS9eP874AWJ",
   "metadata": {
    "id": "_DS9eP874AWJ"
   },
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wwGmj5DY4TKO",
   "metadata": {
    "id": "wwGmj5DY4TKO"
   },
   "outputs": [],
   "source": [
    "# Finding user-books interactions distribution\n",
    "count_interactions = df.groupby(__________).____________\n",
    "count_interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ZcsJbzb6BIX",
   "metadata": {
    "id": "7ZcsJbzb6BIX"
   },
   "outputs": [],
   "source": [
    "# Plotting user-item interactions distribution\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "\n",
    "sns.histplot(__________)\n",
    "\n",
    "plt.xlabel('Number of Interactions by Users')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XZ7ISu5rI6zB",
   "metadata": {
    "id": "XZ7ISu5rI6zB"
   },
   "source": [
    "**Observations:______**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3SiTfmJzJJW7",
   "metadata": {
    "id": "3SiTfmJzJJW7"
   },
   "source": [
    "**As we have now explored the data, let's start building Recommendation Systems**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aISxUcit7hmB",
   "metadata": {
    "id": "aISxUcit7hmB"
   },
   "source": [
    "## **Model 1: Create Rank-Based Recommendation System**\n",
    "\n",
    "- Rank-based recommendation systems provide recommendations based on the most popular items. This kind of recommendation system is useful when we have cold start problems. Cold start refers to the issue when we get a new user into the system and the machine is not able to recommend book to the new user, as the user did not have any historical interactions in the dataset. In those cases, we can use rank-based recommendation system to recommend book to the new user.\n",
    "\n",
    "- To build the rank-based recommendation system, we take average of all the ratings provided to each book and then rank them based on their average rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FzbxIeuR6HE4",
   "metadata": {
    "id": "FzbxIeuR6HE4"
   },
   "outputs": [],
   "source": [
    "# Calculating average ratings for each book_id\n",
    "average_rating = ________________________\n",
    "\n",
    "# Calculating the count of ratings for each book_id\n",
    "count_rating = __________________________\n",
    "\n",
    "# Making a dataframe with the count and average of ratings\n",
    "final_rating = __________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7r9ua1fl90jv",
   "metadata": {
    "id": "7r9ua1fl90jv"
   },
   "outputs": [],
   "source": [
    "final_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s0RCOWp0ANMW",
   "metadata": {
    "id": "s0RCOWp0ANMW"
   },
   "outputs": [],
   "source": [
    "final_rating['rating_count'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iKvi8-qKCMck",
   "metadata": {
    "id": "iKvi8-qKCMck"
   },
   "source": [
    "Now, let's create a function to find the **top n books** for a recommendation based on the average ratings of books. We can also add a **threshold for a minimum number of interactions** for a book to be considered for recommendation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zM8EYyhOAX2F",
   "metadata": {
    "id": "zM8EYyhOAX2F"
   },
   "outputs": [],
   "source": [
    "def top_n_books(data, n, min_interaction=100):\n",
    "    \n",
    "    # Finding books with minimum number of interactions\n",
    "    recommendations = ___________________________________\n",
    "    \n",
    "    # Sorting values w.r.t. average rating \n",
    "    recommendations = recommendations.sort_values(________________)\n",
    "\n",
    "    return recommendations.index[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p9oZBQdNCSO5",
   "metadata": {
    "id": "p9oZBQdNCSO5"
   },
   "source": [
    "We can **use this function with different n's and minimum interactions** to get books to recommend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Z-LO36o8CWRN",
   "metadata": {
    "id": "Z-LO36o8CWRN"
   },
   "source": [
    "##### **Recommending top 5 Book with 10 minimum interactions based on popularity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2HZPjSzLCFEF",
   "metadata": {
    "id": "2HZPjSzLCFEF"
   },
   "outputs": [],
   "source": [
    "res = list(top_n_books(final_rating, 5, 10))\n",
    "# Name of the books\n",
    "list_of_books = []\n",
    "for i in res:\n",
    "    list_of_books.append(df[df['book_id']== str(i) ]['Book-Title'].unique()[0])\n",
    "list_of_books"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766caa66",
   "metadata": {
    "id": "766caa66"
   },
   "source": [
    "##### Recommending top 5 Book with 100 minimum interactions based on popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jjgYTTigCI39",
   "metadata": {
    "id": "jjgYTTigCI39"
   },
   "outputs": [],
   "source": [
    "res2 = list(top_n_books(________________))\n",
    "# Name of the books\n",
    "list_of_book = []\n",
    "for i in res2:\n",
    "    list_of_book.append(____________________)\n",
    "list_of_book"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ugkFNZcOwNcO",
   "metadata": {
    "id": "ugkFNZcOwNcO"
   },
   "source": [
    "## **Model 2: Collaborative Filtering Based Recommendation System**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0GSl8Y8OwbGj",
   "metadata": {
    "id": "0GSl8Y8OwbGj"
   },
   "source": [
    "In this type of recommendation system, we do not need any information about the users or items. We only need user-item interaction data to build a collaborative recommendation system. For example: \n",
    "<ol>\n",
    "    <li><b>Ratings</b> provided by users. For example - ratings of books on Goodreads, movie ratings on IMDB, etc.</li>\n",
    "    <li><b>Likes</b> of users on different Facebook posts, likes on youtube videos</li>\n",
    "    <li><b>Use/buying</b> of a product by users. For example - buying different items on e-commerce sites</li>\n",
    "    <li><b>Reading</b> of articles by readers on various blogs</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8L2QuVSvwd-G",
   "metadata": {
    "id": "8L2QuVSvwd-G"
   },
   "source": [
    "#### **Types of Collaborative Filtering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zfP0EAA0wgbe",
   "metadata": {
    "id": "zfP0EAA0wgbe"
   },
   "source": [
    "- Similarity/Neighborhood based\n",
    "- Model based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OdXiKwmPwoJ4",
   "metadata": {
    "id": "OdXiKwmPwoJ4"
   },
   "source": [
    "Below we are building a similarity-based recommendation system using cosine similarity and using KNN to find similar users who are the nearest neighbor to the given user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kyputF-CrIBW",
   "metadata": {
    "id": "kyputF-CrIBW"
   },
   "outputs": [],
   "source": [
    "# To compute the accuracy of models\n",
    "from surprise import accuracy\n",
    "\n",
    "# Class is used to parse a file containing ratings, data should be in the structure - user ; item ; rating\n",
    "from surprise.reader import Reader\n",
    "\n",
    "# Class for loading datasets\n",
    "from surprise.dataset import Dataset\n",
    "\n",
    "# For tuning model hyperparameters\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# For splitting the rating data in train and test dataset\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# For implementing similarity-based recommendation system\n",
    "from surprise.prediction_algorithms.knns import KNNBasic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zwGNrk5zrSGo",
   "metadata": {
    "id": "zwGNrk5zrSGo"
   },
   "source": [
    "**Before building the recommendation systems, let's  go over some some basic terminologies we are going to use:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h2Dpz4nSrU0m",
   "metadata": {
    "id": "h2Dpz4nSrU0m"
   },
   "source": [
    "**Relevant item** - An item (book in this case) that is actually **rated higher than the threshold rating (here 7)** is relevant, if the **actual rating is below the threshold then it is a non-relevant item**.  \n",
    "\n",
    "**Recommended item** - An item that's **predicted rating is higher than the threshold (here 7) is a recommended item**, if the **predicted rating is below the threshold then that book will not be recommended to the user**.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yCel8rK0rqnF",
   "metadata": {
    "id": "yCel8rK0rqnF"
   },
   "source": [
    "**False Negative (FN)** - It is the **frequency of relevant items that are not recommended to the user**. If the relevant items are not recommended to the user, then the user might not buy the product/item. This would result in the **loss of opportunity for the service provider** which they would like to minimize.\n",
    "\n",
    "**False Positive (FP)** - It is the **frequency of recommended items that are actually not relevant**. In this case, the recommendation system is not doing a good job of finding and recommending the relevant items to the user. This would result in **loss of resources for the service provider** which they would also like to minimize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v0BCB6Xpr0Jf",
   "metadata": {
    "id": "v0BCB6Xpr0Jf"
   },
   "source": [
    "**Recall** - It is the **fraction of actually relevant items that are recommended to the user** i.e. if out of 10 relevant books, 6 are recommended to the user then recall is 0.60. Higher the value of recall better is the model. It is one of the metrics to do the performance assessment of classification models.\n",
    "\n",
    "**Precision** - It is the **fraction of recommended items that are relevant actually** i.e. if out of 10 recommended items, 6 are found relevant by the user then precision is 0.60. The higher the value of precision better is the model. It is one of the metrics to do the performance assessment of classification models.\n",
    "\n",
    "**While making a recommendation system it becomes customary to look at the performance of the model. In terms of how many recommendations are relevant and vice-versa, below are the two most used performance metrics used in the assessment of recommendation systems.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NBYhDklsr8QO",
   "metadata": {
    "id": "NBYhDklsr8QO"
   },
   "source": [
    "### **Precision@k and Recall@ k**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BbEvTLAtr_3b",
   "metadata": {
    "id": "BbEvTLAtr_3b"
   },
   "source": [
    "**Precision@k** - It is the **fraction of recommended items that are relevant in `top k` predictions**. Value of k is the number of recommendations to be provided to the user. One can choose a variable number of recommendations to be given to a unique user.  \n",
    "\n",
    "\n",
    "**Recall@k** - It is the **fraction of relevant items that are recommended to the user in `top k` predictions**.\n",
    "\n",
    "**F1-Score@k** - It is the **harmonic mean of Precision@k and Recall@k**. When **precision@k and recall@k both seem to be important** then it is useful to use this metric because it is representative of both of them. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uKcCNuKusG-d",
   "metadata": {
    "id": "uKcCNuKusG-d"
   },
   "source": [
    "### **Some useful functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8wtW3BvUsJNT",
   "metadata": {
    "id": "8wtW3BvUsJNT"
   },
   "source": [
    "- The following function takes the **recommendation model** as input and gives the **precision@k and recall@k** for that model.  \n",
    "- To compute **precision and recall**, **top k** predictions are taken under consideration for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "P7wO6rPEsNlN",
   "metadata": {
    "id": "P7wO6rPEsNlN"
   },
   "outputs": [],
   "source": [
    "def precision_recall_at_k(model, k=10, threshold=7):\n",
    "\n",
    "    # First map the predictions to each user\n",
    "    user_est_true = defaultdict(list)\n",
    "    \n",
    "    # Making predictions on the test data\n",
    "    predictions=model.test(testset)\n",
    "    \n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        # When n_rec_k is 0, Precision is undefined. We here set Precision to 0 when n_rec_k is 0.\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. We here set Recall to 0 when n_rel is 0.\n",
    "\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "    \n",
    "    # Mean of all the predicted precisions is calculated.\n",
    "    precision = round((sum(prec for prec in precisions.values()) / len(precisions)),3)\n",
    "    # Mean of all the predicted recalls is calculated.\n",
    "    recall = round((sum(rec for rec in recalls.values()) / len(recalls)),3)\n",
    "    \n",
    "    accuracy.rmse(predictions)\n",
    "    print('Precision: ', precision) # Command to print the overall precision\n",
    "    print('Recall: ', recall) # Command to print the overall recall\n",
    "    print('F_1 score: ', round((2*precision*recall)/(precision+recall),3)) # Formula to compute the F-1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aqQwqRbLwsXq",
   "metadata": {
    "id": "aqQwqRbLwsXq"
   },
   "source": [
    "**Let's encode the user_id and book_id for simplicity, also encoding them will not make any change in the prediction.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dzAcHitliynT",
   "metadata": {
    "id": "dzAcHitliynT"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "data=df[['user_id','book_id']].apply(LabelEncoder().___________) # Hint: Use fit_transform\n",
    "data['rating']=df['rating']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "J5FLjvVRDE3A",
   "metadata": {
    "id": "J5FLjvVRDE3A"
   },
   "outputs": [],
   "source": [
    "# Creating a copy of the above dataset for further use\n",
    "df_rating = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BFxRT5a8-9oR",
   "metadata": {
    "id": "BFxRT5a8-9oR"
   },
   "outputs": [],
   "source": [
    "# Calculating average ratings\n",
    "average_rating = ____________________\n",
    "\n",
    "# Calculating the count of ratings\n",
    "count_rating = ______________________\n",
    "\n",
    "# Updating the final_rating dataframe with the new encoded book_id count and average of ratings based on the new dataframe\n",
    "final_rating = ______________________\n",
    "final_rating.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gfLimBYByEMT",
   "metadata": {
    "id": "gfLimBYByEMT"
   },
   "source": [
    "Below we are loading the `data` dataset, which is a pandas dataframe, into a different format called `surprise.dataset.DatasetAutoFolds` which is required by this library. To do this, we will be using the classes `Reader` and `Dataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i4AuGT6GyHP5",
   "metadata": {
    "id": "i4AuGT6GyHP5"
   },
   "source": [
    "**Making the dataset into surprise dataset and splitting it into train and test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5yM50jxND1",
   "metadata": {
    "id": "9c5yM50jxND1"
   },
   "outputs": [],
   "source": [
    "# Instantiating Reader scale with expected rating scale\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "\n",
    "# Loading the rating dataset\n",
    "data = Dataset.load_from_df(data[['user_id', 'book_id', 'rating']], reader)\n",
    "\n",
    "# Splitting the data into train and test dataset\n",
    "trainset, testset = train_test_split(data, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4MqqyFpsyXE2",
   "metadata": {
    "id": "4MqqyFpsyXE2"
   },
   "source": [
    "Now, we are ready to build the first baseline similarity based recommendation system using cosine similarity and KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4jUGdQ67ya00",
   "metadata": {
    "id": "4jUGdQ67ya00"
   },
   "source": [
    "### **User-Based Collaborative Filtering Recommendation System**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iplcJx5CyTyQ",
   "metadata": {
    "id": "iplcJx5CyTyQ"
   },
   "outputs": [],
   "source": [
    "sim_options = {'name': ________,\n",
    "               'user_based': ______}\n",
    "\n",
    "algo_knn_user = KNNBasic(_______________)\n",
    "\n",
    "# Train the algorithm on the train set, and predict ratings for the test set\n",
    "algo_knn_user._______________\n",
    "\n",
    "# Let us compute precision@k, recall@k, and f_1 score with k =10. Hint: use precision_recall_at_k() function defined above\n",
    "__________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QRbp24smyjY4",
   "metadata": {
    "id": "QRbp24smyjY4"
   },
   "source": [
    "**Observations:______**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2NZVLDEFy4iI",
   "metadata": {
    "id": "2NZVLDEFy4iI"
   },
   "source": [
    "**What is the predicted rating for the user with userId=1326 and for book_id=12126?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bPQu2nHkyhIe",
   "metadata": {
    "id": "bPQu2nHkyhIe"
   },
   "outputs": [],
   "source": [
    "algo_knn_user.predict(_____,______, r_ui=8, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TMr8wc6p2HIF",
   "metadata": {
    "id": "TMr8wc6p2HIF"
   },
   "source": [
    "**Observations:______**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UGvtI7Sn2YOi",
   "metadata": {
    "id": "UGvtI7Sn2YOi"
   },
   "source": [
    "Let's predict the rating for the same `userId=1326` but for a book which this user has not a rated before, i.e., `book_id=2150`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Qc4OsGq_zVe4",
   "metadata": {
    "id": "Qc4OsGq_zVe4"
   },
   "outputs": [],
   "source": [
    "algo_knn_user.predict(______,______, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6Kth-x7Y2jf1",
   "metadata": {
    "id": "6Kth-x7Y2jf1"
   },
   "source": [
    "### **Improving similarity based recommendation system by tuning its hyperparameters**\n",
    "\n",
    "Below we will be tuning hyperparameters for the `KNNBasic` algorithms. Let's try to understand different hyperparameters of KNNBasic algorithm - \n",
    "\n",
    "- **k** (int) – The (max) number of neighbors to take into account for aggregation (see this note). Default is 40.\n",
    "- **min_k** (int) – The minimum number of neighbors to take into account for aggregation. If there are not enough neighbors, the prediction is set to the global mean of all ratings. Default is 1.\n",
    "- **sim_options** (dict) – A dictionary of options for the similarity measure. And there are four similarity measures available in surprise - \n",
    "    - cosine\n",
    "    - msd (default)\n",
    "    - pearson\n",
    "    - pearson baseline\n",
    "    \n",
    "For more details please refer the official documentation https://surprise.readthedocs.io/en/stable/knn_inspired.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opEuwl6Q2m-n",
   "metadata": {
    "id": "opEuwl6Q2m-n"
   },
   "source": [
    "**Perform hyperparameter tuning for the baseline user based collaborative filtering recommendation system and find the RMSE for tuned user based collaborative filtering recommendation system.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sK7kuHGn2OEo",
   "metadata": {
    "id": "sK7kuHGn2OEo"
   },
   "outputs": [],
   "source": [
    "# Setting up parameter grid to tune the hyperparameters\n",
    "param_grid = {'k': [20, 30, 40], 'min_k': [3, 6, 9],\n",
    "              'sim_options': {'name': ['msd', 'cosine'],\n",
    "                              'user_based': [True]}\n",
    "              }\n",
    "\n",
    "# Performing 3-fold cross validation to tune the hyperparameters\n",
    "gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse', 'mae'], cv=3, n_jobs=-1)\n",
    "\n",
    "# Fitting the data\n",
    "gs.fit(________)\n",
    "\n",
    "# Best RMSE score\n",
    "print(gs.best_score[_____])\n",
    "\n",
    "# Combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params[_____])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cX0ZInD64Rfi",
   "metadata": {
    "id": "cX0ZInD64Rfi"
   },
   "source": [
    "Now, let's build the **final model by using tuned values of the hyperparameters**, which we received by using **grid search cross-validation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ORddNoEF4UTz",
   "metadata": {
    "id": "ORddNoEF4UTz"
   },
   "outputs": [],
   "source": [
    "# Using the optimal similarity measure for user-based collaborative filtering\n",
    "sim_options = __________________\n",
    "\n",
    "# Creating an instance of KNNBasic with optimal hyperparameter values\n",
    "similarity_algo_optimized = __________________\n",
    "\n",
    "# Training the algorithm on the train set\n",
    "similarity_algo_optimized.____________________\n",
    "\n",
    "# Let us compute precision@k and recall@k with k=10.\n",
    "______________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OzJ2YK6N4h89",
   "metadata": {
    "id": "OzJ2YK6N4h89"
   },
   "source": [
    "**Observations:______**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qLkFFwPt4xu3",
   "metadata": {
    "id": "qLkFFwPt4xu3"
   },
   "source": [
    "**What is the predicted rating for the user with user_id=1326 and for book_id=12126 using the tuned user-based collaborative filtering?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30u0cv1Q4eks",
   "metadata": {
    "id": "30u0cv1Q4eks"
   },
   "outputs": [],
   "source": [
    "similarity_algo_optimized.predict(_____,______, r_ui=8, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CUwWhuohBdh9",
   "metadata": {
    "id": "CUwWhuohBdh9"
   },
   "source": [
    "**Observations:______**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eycrxIspBt1r",
   "metadata": {
    "id": "eycrxIspBt1r"
   },
   "source": [
    "Below we are predicting rating for the same `user_id=1326` but for a book which this user has not a rated before, i.e., `book_id=2150`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cvjtPbzr5Jww",
   "metadata": {
    "id": "cvjtPbzr5Jww"
   },
   "outputs": [],
   "source": [
    "similarity_algo_optimized.predict(_____,______, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_9dUueXNB7RO",
   "metadata": {
    "id": "_9dUueXNB7RO"
   },
   "source": [
    "**Identifying users similar to a given user (nearest neighbors)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1RXVFrXIB-FK",
   "metadata": {
    "id": "1RXVFrXIB-FK"
   },
   "source": [
    "We can find out the similar users to a given user or its nearest neighbors based on this KNNBasic algorithm. Below we are finding 5 most similar user to the `user_id=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8lMm-mP0BxaM",
   "metadata": {
    "id": "8lMm-mP0BxaM"
   },
   "outputs": [],
   "source": [
    "similarity_algo_optimized.get_neighbors(1, k=______)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DNgN6NvbCEIm",
   "metadata": {
    "id": "DNgN6NvbCEIm"
   },
   "source": [
    "### **Implementing the recommendation algorithm based on optimized KNNBasic model**\n",
    "\n",
    "Below we will be implementing a function where the input parameters are:\n",
    "\n",
    "- data: a rating dataset\n",
    "- user_id:  user_id against which we want the recommendations\n",
    "- top_n: the number of items we want to recommend\n",
    "- algo: the algorithm we want to use to predict the ratings\n",
    "- The output of the function is a **set of top_n items** recommended for the given user_id based on the given algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IdzEUe5bCAd8",
   "metadata": {
    "id": "IdzEUe5bCAd8"
   },
   "outputs": [],
   "source": [
    "def get_recommendations(data, user_id, top_n, algo):\n",
    "    \n",
    "    # Creating an empty list to store the recommended book ids\n",
    "    recommendations = []\n",
    "    \n",
    "    # Creating an user item interactions matrix \n",
    "    user_item_interactions_matrix = data.pivot(index='user_id', columns='book_id', values='rating')\n",
    "    \n",
    "    # Extracting those book ids which the user_id has not interacted with yet\n",
    "    non_interacted_items = user_item_interactions_matrix.loc[user_id][user_item_interactions_matrix.loc[user_id].isnull()].index.tolist()\n",
    "    \n",
    "    # Looping through each of the book id which user_id has not interacted with yet\n",
    "    for book_id in non_interacted_items:\n",
    "        \n",
    "        # Predicting the ratings for those non interacted book ids by this user\n",
    "        est = algo.predict(user_id, book_id).est\n",
    "        \n",
    "        # Appending the predicted ratings\n",
    "        recommendations.append((book_id, est))\n",
    "\n",
    "    # Sorting the predicted ratings in descending order\n",
    "    recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return recommendations[:top_n] # Returning top n predicted rating items for this user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KZA83Q06CHXt",
   "metadata": {
    "id": "KZA83Q06CHXt"
   },
   "outputs": [],
   "source": [
    "df_rating=df_rating.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guT2JNkPEtYQ",
   "metadata": {
    "id": "guT2JNkPEtYQ"
   },
   "source": [
    "**Predicting the top 5 items for userId=1 using the similarity-based recommendation system**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NC_rcSmCEp_0",
   "metadata": {
    "id": "NC_rcSmCEp_0"
   },
   "outputs": [],
   "source": [
    "# Hint: use the above get_recommendations function and use similarity_algo_optimized as the algo\n",
    "recommendations = ____________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DRGySEPsExCn",
   "metadata": {
    "id": "DRGySEPsExCn"
   },
   "outputs": [],
   "source": [
    "# Building the dataframe for above recommendations with columns \"book_id\" and \"predicted_ratings\"\n",
    "pd.DataFrame(recommendations, columns=['book_Id', 'predicted_ratings'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebJXqOfU3T6z",
   "metadata": {
    "id": "ebJXqOfU3T6z"
   },
   "source": [
    "### **Correcting the Ratings and Ranking the above books**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Xp_Z5PwX3X2C",
   "metadata": {
    "id": "Xp_Z5PwX3X2C"
   },
   "source": [
    "While comparing the ratings of two books, it is not only the **ratings** that describe the **likelihood of the user to that book**. Along with the rating the **number of users who have read that book** also becomes a important point to consider. Due to this, we have calculated the **\"corrected_ratings\"** for each book. Commonly higher the **\"rating_count\" of a book more reliable the rating is**. To interpret the above concept, a **book rated 8 with rating_count 5 is less liked in comparison to a book rated 7 with a rating count of 50**. It has been **empirically found that the likelihood of the book is directly proportional to the inverse of the square root of the rating_count of the book**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nqpj9QVy3-uE",
   "metadata": {
    "id": "nqpj9QVy3-uE"
   },
   "outputs": [],
   "source": [
    "def ranking_books(recommendations, final_rating):\n",
    "  # Sort the books based on ratings count\n",
    "  ranked_books = final_rating.loc[[items[0] for items in recommendations]].sort_values('rating_count', ascending=False)[['rating_count']].reset_index()\n",
    "\n",
    "  # Merge with the recommended books to get predicted ratings\n",
    "  ranked_books = ranked_books.merge(pd.DataFrame(recommendations, columns=['book_id', 'predicted_ratings']), on='book_id', how='inner')\n",
    "\n",
    "  # Rank the books based on corrected ratings\n",
    "  ranked_books['corrected_ratings'] = ranked_books['predicted_ratings'] - 1 / np.sqrt(ranked_books['rating_count'])\n",
    "\n",
    "  # Sort the books based on corrected ratings\n",
    "  ranked_books = ranked_books.sort_values('corrected_ratings', ascending=False)\n",
    "  \n",
    "  return ranked_books"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kGNeUmuv49o4",
   "metadata": {
    "id": "kGNeUmuv49o4"
   },
   "source": [
    "**Note:** In the **above-corrected rating formula**, we can add the **quantity `1/np.sqrt(n)` instead of subtracting it to get more optimistic predictions**. But here we are **subtracting this quantity**, as there are some books with ratings 10 and **we can't have a rating more than 10 for a book**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6_0a4d6e44uR",
   "metadata": {
    "id": "6_0a4d6e44uR"
   },
   "outputs": [],
   "source": [
    "# Applying the ranking_books function and sorting it based on corrected ratings\n",
    "ranking_books(recommendations, final_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t3k3J1OvT1so",
   "metadata": {
    "id": "t3k3J1OvT1so"
   },
   "source": [
    "### **Model 3: Item based Collaborative Filtering Recommendation System**\n",
    "\n",
    "* We have seen **user-user similarity-based collaborative filtering**. Now, let us look into similarity-based collaborative filtering where similarity is calculated **between items**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QQZMJ4gdEzvk",
   "metadata": {
    "id": "QQZMJ4gdEzvk"
   },
   "outputs": [],
   "source": [
    "# Defining similarity measure\n",
    "sim_options = {'name': 'cosine',\n",
    "               'user_based': _________}\n",
    "\n",
    "# Defining nearest neighbour algorithm\n",
    "algo_knn_item = ___________________\n",
    "\n",
    "# Train the algorithm on the train set \n",
    "algo_knn_item._____________________\n",
    "\n",
    "# Let us compute precision@k, recall@k, and f_1 score with k=10\n",
    "__________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leLh-NaVUDEN",
   "metadata": {
    "id": "leLh-NaVUDEN"
   },
   "source": [
    "**Observations:______**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zu6zKkCMX0m6",
   "metadata": {
    "id": "zu6zKkCMX0m6"
   },
   "source": [
    "**What is the predicted  rating for an user with user_id=1326 and for book_id=12126?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PEGAaPAQT9Gu",
   "metadata": {
    "id": "PEGAaPAQT9Gu"
   },
   "outputs": [],
   "source": [
    "# Predict rating for user_id=1326 and for book_id= 12126\n",
    "_________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xae5b7CPYBNM",
   "metadata": {
    "id": "Xae5b7CPYBNM"
   },
   "outputs": [],
   "source": [
    "# Predict rating for user_id=1326 and for book_id= 2150\n",
    "_________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ogoclhUOYVyR",
   "metadata": {
    "id": "ogoclhUOYVyR"
   },
   "source": [
    "**Tuning the baseline item-based collaborative filtering recommendation system's hyperparameters and determining the RMSE for the tuned item-based collaborative filtering recommendation system**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SgwHzd-BYDL1",
   "metadata": {
    "id": "SgwHzd-BYDL1"
   },
   "outputs": [],
   "source": [
    "# Setting up parameter grid to tune the hyperparameters\n",
    "param_grid = {'k': [_______], 'min_k': [______],\n",
    "              'sim_options': {'name': [_______],\n",
    "                              'user_based':________}\n",
    "              }\n",
    "\n",
    "# Performing 3-fold cross validation to tune the hyperparameters\n",
    "grid_obj = GridSearchCV(____________________)\n",
    "\n",
    "# Fitting the data\n",
    "grid_obj.fit(data)\n",
    "\n",
    "# Best RMSE score\n",
    "print(grid_obj.best_score[______])\n",
    "\n",
    "# Combination of parameters that gave the best RMSE score\n",
    "print(grid_obj.best_params[______])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bKaNx5o3Dkdj",
   "metadata": {
    "id": "bKaNx5o3Dkdj"
   },
   "source": [
    "Now, let's build the **final model** by using **optimal values of the hyperparameters** which we received by using grid search cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XngftF5hYndx",
   "metadata": {
    "id": "XngftF5hYndx"
   },
   "outputs": [],
   "source": [
    "# Creating an instance of KNNBasic with optimal hyperparameter values\n",
    "similarity_algo_optimized_item = KNNBasic(_________________________)\n",
    "\n",
    "# Training the algorithm on the train set\n",
    "similarity_algo_optimized_item._________________\n",
    "\n",
    "# Let us compute precision@k and recall@k with k=10\n",
    "______________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aeMyoKYrCH",
   "metadata": {
    "id": "43aeMyoKYrCH"
   },
   "source": [
    "**Observations:______**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zp5vWSgAZD8r",
   "metadata": {
    "id": "zp5vWSgAZD8r"
   },
   "source": [
    "**Let's predict the rating for an user with user_id=1326 and for book_id= 12126.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369ijl_vYpJz",
   "metadata": {
    "id": "369ijl_vYpJz"
   },
   "outputs": [],
   "source": [
    "# Predict rating for user_id=1326 and for book_id= 12126\n",
    "_________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VBenqFb3Y9lS",
   "metadata": {
    "id": "VBenqFb3Y9lS"
   },
   "outputs": [],
   "source": [
    "# Predict rating for user_id=1326 and for book_id= 2150\n",
    "_________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1js7ddxsZ6pe",
   "metadata": {
    "id": "1js7ddxsZ6pe"
   },
   "source": [
    "**Observations:______**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tEpMkj6bZ_yV",
   "metadata": {
    "id": "tEpMkj6bZ_yV"
   },
   "source": [
    "### **Identifying similar items to a given item (nearest neighbors)**\n",
    "\n",
    "We can also find out the similar items to a given item or its nearest neighbors based on this KNNBasic algorithm. Below we are finding 5 most similar items to the `BookId=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zD1ckXRfZ89n",
   "metadata": {
    "id": "zD1ckXRfZ89n"
   },
   "outputs": [],
   "source": [
    "similarity_algo_optimized_item._______________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rECVFIlsaF51",
   "metadata": {
    "id": "rECVFIlsaF51"
   },
   "source": [
    "#### Predicted top 5 books for user_id=1 with similarity based recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "F3qBa9TnaC6M",
   "metadata": {
    "id": "F3qBa9TnaC6M"
   },
   "outputs": [],
   "source": [
    "recommendations = _____________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Cdub3MKBaLsG",
   "metadata": {
    "id": "Cdub3MKBaLsG"
   },
   "outputs": [],
   "source": [
    "# Building the dataframe for above recommendations with columns \"book_id\" and \"predicted_ratings\"\n",
    "pd.DataFrame(__________________________________)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f90df9",
   "metadata": {
    "id": "91f90df9"
   },
   "outputs": [],
   "source": [
    "# Applying the ranking_books function and sorting it based on corrected ratings \n",
    "________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vg-ZeK9tFEs0",
   "metadata": {
    "id": "vg-ZeK9tFEs0"
   },
   "source": [
    "## **Model 4: Matrix Factorization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rvT1kLFeRwVn",
   "metadata": {
    "id": "rvT1kLFeRwVn"
   },
   "source": [
    "Model-based Collaborative Filtering is a **personalized recommendation system**. The recommendations are based on the past behavior of the user and it is not dependent on any additional information. We use **latent features** to find recommendations for each user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jaw7mmjbR7kY",
   "metadata": {
    "id": "jaw7mmjbR7kY"
   },
   "source": [
    "**Latent Features:** The features that are not present in the empirical data but can be inferred from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WdRtVlogUNev",
   "metadata": {
    "id": "WdRtVlogUNev"
   },
   "source": [
    "### **Singular Value Decomposition (SVD)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FcOwJM1EUOXn",
   "metadata": {
    "id": "FcOwJM1EUOXn"
   },
   "source": [
    "SVD is used to **compute the latent features** from the **user-item matrix** that we already learned earlier. But SVD does not work when we **miss values** in the **user-item matrix**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gwRE4P5EUZ5s",
   "metadata": {
    "id": "gwRE4P5EUZ5s"
   },
   "source": [
    "#### **Building a baseline matrix factorization recommendation system**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49s7qJDDEuI6",
   "metadata": {
    "id": "49s7qJDDEuI6"
   },
   "outputs": [],
   "source": [
    "# Using SVD matrix factorization\n",
    "svd = SVD(________)\n",
    "\n",
    "# Training the algorithm on the train set\n",
    "svd.___________\n",
    "\n",
    "# Let us compute precision@k and recall@k with k=10\n",
    "____________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h7Dv6qZrau-Z",
   "metadata": {
    "id": "h7Dv6qZrau-Z"
   },
   "source": [
    "**Observations:______**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dvVgqxzpbpLd",
   "metadata": {
    "id": "dvVgqxzpbpLd"
   },
   "source": [
    "**What is the predicted  rating for an user with user_id=1326 and for book_id= 12126?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oocJG4ABUe_d",
   "metadata": {
    "id": "oocJG4ABUe_d"
   },
   "outputs": [],
   "source": [
    "# Making prediction for user_id 1326 and book_id 12126\n",
    "____________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "udpGB5Jbb71r",
   "metadata": {
    "id": "udpGB5Jbb71r"
   },
   "outputs": [],
   "source": [
    "# Making prediction for user_id 1326 and book_id 2150\n",
    "____________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nJCPOs6Icv2-",
   "metadata": {
    "id": "nJCPOs6Icv2-"
   },
   "source": [
    "### **Improving matrix factorization based recommendation system by tuning its hyperparameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PG489i0bcxBZ",
   "metadata": {
    "id": "PG489i0bcxBZ"
   },
   "source": [
    "In SVD, rating is predicted as: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oKQ7Ph5Ic0UR",
   "metadata": {
    "id": "oKQ7Ph5Ic0UR"
   },
   "source": [
    "$$\\hat{r}_{u i}=\\mu+b_{u}+b_{i}+q_{i}^{T} p_{u}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dxTSTeNPc6xB",
   "metadata": {
    "id": "dxTSTeNPc6xB"
   },
   "source": [
    "If user $u$ is unknown, then the bias $b_{u}$ and the factors $p_{u}$ are assumed to be zero. The same applies for item $i$ with $b_{i}$ and $q_{i}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "n0WBOxxmc99M",
   "metadata": {
    "id": "n0WBOxxmc99M"
   },
   "source": [
    "To estimate all the unknown, we minimize the following regularized squared error:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AnCcV1gmc_A9",
   "metadata": {
    "id": "AnCcV1gmc_A9"
   },
   "source": [
    "$$\\sum_{r_{u i} \\in R_{\\text {train }}}\\left(r_{u i}-\\hat{r}_{u i}\\right)^{2}+\\lambda\\left(b_{i}^{2}+b_{u}^{2}+\\left\\|q_{i}\\right\\|^{2}+\\left\\|p_{u}\\right\\|^{2}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cNM8qlB1dEQl",
   "metadata": {
    "id": "cNM8qlB1dEQl"
   },
   "source": [
    "The minimization is performed by a very straightforward **stochastic gradient descent**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lS0b4MhedG3P",
   "metadata": {
    "id": "lS0b4MhedG3P"
   },
   "source": [
    "$$\\begin{aligned} b_{u} & \\leftarrow b_{u}+\\gamma\\left(e_{u i}-\\lambda b_{u}\\right) \\\\ b_{i} & \\leftarrow b_{i}+\\gamma\\left(e_{u i}-\\lambda b_{i}\\right) \\\\ p_{u} & \\leftarrow p_{u}+\\gamma\\left(e_{u i} \\cdot q_{i}-\\lambda p_{u}\\right) \\\\ q_{i} & \\leftarrow q_{i}+\\gamma\\left(e_{u i} \\cdot p_{u}-\\lambda q_{i}\\right) \\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UsxGzpxadKB1",
   "metadata": {
    "id": "UsxGzpxadKB1"
   },
   "source": [
    "There are many hyperparameters to tune in this algorithm, you can find a full list of hyperparameters [here](https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eg2iehvSdLDP",
   "metadata": {
    "id": "eg2iehvSdLDP"
   },
   "source": [
    "Below we will be tuning only three hyperparameters:\n",
    "- **n_epochs**: The number of iteration of the SGD algorithm\n",
    "- **lr_all**: The learning rate for all parameters\n",
    "- **reg_all**: The regularization term for all parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qWyGhAtWcXe_",
   "metadata": {
    "id": "qWyGhAtWcXe_"
   },
   "outputs": [],
   "source": [
    "# Set the parameter space to tune\n",
    "param_grid = {'n_epochs': [_________], 'lr_all': [_________],\n",
    "              'reg_all': [__________]}\n",
    "\n",
    "# Performing 3-fold gridsearch cross validation\n",
    "gs_ = GridSearchCV(___________________)\n",
    "\n",
    "# Fitting data\n",
    "gs_.fit(data)\n",
    "\n",
    "# Best RMSE score\n",
    "print(gs_.best_score['rmse'])\n",
    "\n",
    "# Combination of parameters that gave the best RMSE score\n",
    "print(gs_.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qEASIxD7dZT_",
   "metadata": {
    "id": "qEASIxD7dZT_"
   },
   "source": [
    "Now, let's **build the final model** by using **optimal values** of the hyperparameters which we received by using grid search cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "W_dL_jrhdS9a",
   "metadata": {
    "id": "W_dL_jrhdS9a"
   },
   "outputs": [],
   "source": [
    "# Building the optimized SVD modelh\n",
    "svd_optimized = SVD(____________)\n",
    "\n",
    "# Training the algorithm on the train set\n",
    "svd_optimized=svd_optimized._____________\n",
    "\n",
    "# Let us compute precision@k and recall@k with k=10\n",
    "___________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Smd7zhi-fsBt",
   "metadata": {
    "id": "Smd7zhi-fsBt"
   },
   "source": [
    "**Observations:______**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6u2Ppqk2f76N",
   "metadata": {
    "id": "6u2Ppqk2f76N"
   },
   "source": [
    "**Let's predict the rating for an user with user_id=1326 and for book_id=12126.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IgzNelmrfGH8",
   "metadata": {
    "id": "IgzNelmrfGH8"
   },
   "outputs": [],
   "source": [
    "# Making prediction for user_id 1326 and book_id 12126\n",
    "______________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9yDpbHWjgKWj",
   "metadata": {
    "id": "9yDpbHWjgKWj"
   },
   "outputs": [],
   "source": [
    "# Making prediction for user_id 1326 and book_id 2150\n",
    "______________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jNRxiE4Fg1SH",
   "metadata": {
    "id": "jNRxiE4Fg1SH"
   },
   "source": [
    "**Now, let's recommend the books using the optimized svd model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbLn0VJ4gRpL",
   "metadata": {
    "id": "dbLn0VJ4gRpL"
   },
   "outputs": [],
   "source": [
    "# Getting top 5 recommendations for user_id 1 using \"svd_optimized\" algorithm.\n",
    "svd_recommendations = get_recommendations(________, 1, 5, _________)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exAPgE4-hIA_",
   "metadata": {
    "id": "exAPgE4-hIA_"
   },
   "outputs": [],
   "source": [
    "# Ranking book based on above recommendations. Hint: use ranking_books function\n",
    "ranking_books(_______, _________)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1RDDp5cbhR3I",
   "metadata": {
    "id": "1RDDp5cbhR3I"
   },
   "source": [
    "## **Conclusions:____**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RS_Book_Recommendation_Learner_Notebook.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
